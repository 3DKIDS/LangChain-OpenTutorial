{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example: Prompt+Model+OutputParser\n",
    "\n",
    "- Author: [ChangJun Lee](https://www.linkedin.com/in/cjleeno1/)\n",
    "- Design: []()\n",
    "- Peer Review: [Erika](https://github.com/ErikaPark)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The most fundamental and commonly used case involves linking a prompt template with a model. To illustrate how this works, let us create a chain that asks for the capital cities of various countries.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Utilizing Prompt Templates](#utilizing-prompt-templates)\n",
    "- [Chain Creation](#chain-creation)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain ChatOpenAI API reference](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n",
    "- [LangChain Core Output Parsers](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.list.CommaSeparatedListOutputParser.html#)\n",
    "- [Python List Tutorial](https://docs.python.org/3.13/tutorial/datastructures.html)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_community\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set local environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it. \n",
    "\n",
    "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration File for Managing API Key as an Global Environment Variable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API KEY Information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up LangSmith tracking: https://smith.langchain.com\n",
    "from langsmith import utils\n",
    "\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Prompt Templates\n",
    "\n",
    "`PromptTemplate`\n",
    "\n",
    "- A prompt template is used to create a complete prompt string by incorporating the user's input variables.\n",
    "- Usage\n",
    "  - `template`: A template string is a predefined format where curly braces '{}' are used to represent variables.\n",
    "\n",
    "  - `input_variables`: The names of the variables to be inserted within the curly braces are defined as a list.\n",
    "\n",
    "`input_variables`\n",
    "\n",
    "- `input_variables` is a list that defines the names of the variables used in the `PromptTemplate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `from_template()` method is used to create a `PromptTemplate` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define template\n",
    "template = \"What is the capital of {country}?\"\n",
    "\n",
    "# Create a `PromptTemplate` object using the `from_template` method.\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Korea?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"Korea\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of USA?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"USA\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Creation\n",
    "\n",
    "### LCEL (LangChain Expression Language)\n",
    "\n",
    "Here, we use LCEL to combine various components into a single chain.\n",
    "\n",
    "![lcel.png](./assets/lcel.png)\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "The `|` symbol works similarly to the [Unix pipe operator](<https://en.wikipedia.org/wiki/Pipeline_(Unix)>), linking different components and passing the output of one component as the input to the next.\n",
    "\n",
    "In this chain, user input is passed to the prompt template, and the output from the prompt template is then forwarded to the model. By examining each component individually, you can understand what happens at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt as a `PromptTemplate` object.\n",
    "prompt = PromptTemplate.from_template(\"Please explain {topic} in simple terms.\")\n",
    "\n",
    "\n",
    "# Combine the prompt and model into a chain\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling `invoke()`\n",
    "\n",
    "- Input values are provided in the form of a Python dictionary (key-value pairs).  \n",
    "- When calling the `invoke()` function, these input values are passed as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the topic in the `input` dictionary to 'The Principles of Learning in Artificial Intelligence Models'.\n",
    "input = {\"topic\": \"The Principles of Learning in Artificial Intelligence Models\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the basic ideas that guide how these models learn from data. Here are some key principles explained in simple terms:\\n\\n1. **Data-Driven Learning**: AI models learn from data. The more relevant and high-quality data they have, the better they can learn patterns and make predictions. Think of it like a student learning from textbooks; the more information they have, the more they can understand.\\n\\n2. **Generalization**: Once an AI model learns from specific examples, it should be able to apply that knowledge to new, unseen examples. This is like a student who learns math concepts and can solve new problems that they haven't practiced before.\\n\\n3. **Feedback and Adjustment**: AI models often use feedback to improve their performance. When they make mistakes, they can adjust their understanding based on the feedback they receive, similar to how a student learns from their errors on a test.\\n\\n4. **Iteration**: Learning is usually an iterative process. AI models go through many cycles of learning, testing, and refining their knowledge. This is like practicing a skill repeatedly until you get better at it.\\n\\n5. **Feature Extraction**: AI models identify important features or characteristics in the data that help them make decisions. For example, if a model is learning to recognize animals in pictures, it might focus on features like fur patterns or shapes.\\n\\n6. **Overfitting and Underfitting**: These are common problems in learning. Overfitting happens when a model learns too much from the training data, including noise, and performs poorly on new data. Underfitting occurs when a model is too simple to capture the underlying patterns. It's like a student either memorizing answers without understanding or not studying enough to grasp the material.\\n\\n7. **Transfer Learning**: This principle involves taking knowledge gained from one task and applying it to a different but related task. For example, if a model learns to recognize cats, it might use that knowledge to help recognize dogs.\\n\\n8. **Exploration and Exploitation**: In some learning scenarios, models need to balance exploring new possibilities (trying new things) and exploiting known information (using what they already know). This is similar to a student trying different study methods while also sticking to what works best for them.\\n\\nBy following these principles, AI models can effectively learn from data and improve their performance over time, much like how humans learn and adapt.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 498, 'prompt_tokens': 21, 'total_tokens': 519, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'stop', 'logprobs': None}, id='run-2297ac15-f028-48c4-a54a-8da20eb36abb-0', usage_metadata={'input_tokens': 21, 'output_tokens': 498, 'total_tokens': 519, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the `prompt` object and the `model` object using the pipe (`|`) operator.  \n",
    "# Use the `invoke` method to pass the `input`.  \n",
    "# This will return the message generated by the AI model.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of outputting a streaming response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the basic ideas that guide how AI systems learn from data and improve their performance over time. Here are some key principles explained in simple terms:\n",
      "\n",
      "1. **Data is Key**: AI models learn from data. The more quality data they have, the better they can learn. Think of it like a student studying for a test; the more information they have, the better they can prepare.\n",
      "\n",
      "2. **Learning from Examples**: AI models often learn by looking at examples. For instance, if you show an AI many pictures of cats and dogs, it can learn to tell the difference between them. This is similar to how we learn by seeing different examples in school.\n",
      "\n",
      "3. **Feedback Loop**: AI models improve through feedback. When they make a mistake, they can learn from it. For example, if an AI incorrectly identifies a cat as a dog, it can adjust its understanding based on that mistake, much like how we learn from our errors.\n",
      "\n",
      "4. **Generalization**: A good AI model can apply what it has learned to new, unseen data. This means it can recognize a cat it has never seen before, based on what it learned from previous examples. It’s like being able to solve a new math problem using the concepts learned from similar problems.\n",
      "\n",
      "5. **Optimization**: AI models often try to minimize errors or maximize accuracy. They adjust their internal settings (parameters) to find the best way to make predictions or decisions. This is similar to how athletes practice to improve their performance.\n",
      "\n",
      "6. **Transfer Learning**: Sometimes, AI can use knowledge gained from one task to help with another related task. For example, if an AI learns to recognize animals, it might use that knowledge to help identify different breeds of dogs. This is like how learning to ride a bike can help you learn to ride a motorcycle.\n",
      "\n",
      "7. **Continuous Learning**: AI can keep learning over time. As it gets more data or experiences, it can update its knowledge and improve its performance. This is similar to how people continue to learn and grow throughout their lives.\n",
      "\n",
      "8. **Model Complexity**: The structure of the AI model matters. Some problems require simple models, while others need more complex ones. Choosing the right model is like picking the right tool for a job; using the wrong tool can make things harder.\n",
      "\n",
      "In summary, AI models learn from data, improve through feedback, generalize knowledge, and can adapt over time. These principles help guide the development and training of AI systems to make them more effective and efficient."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "\n",
    "An **Output Parser** is a tool designed to transform or process the responses from an AI model into a specific format. Since the model's output is typically provided as free-form text, an **Output Parser** is essential to convert it into a structured format or extract the required data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser() # Directly returns the model's response as a string without modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An output parser is added to the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A processing chain is constructed by connecting the prompt, model, and output parser.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! The principles of learning in artificial intelligence (AI) models can be understood as the basic ideas that guide how these models learn from data. Here are some key principles explained in simple terms:\\n\\n1. **Data is Key**: AI models learn from data. The more relevant and high-quality data you provide, the better the model can learn and make predictions.\\n\\n2. **Learning from Examples**: AI models often learn by looking at examples. For instance, if you want a model to recognize cats in pictures, you show it many pictures of cats and non-cats. The model learns to identify patterns that distinguish cats from other objects.\\n\\n3. **Feedback Loop**: Many AI models improve through feedback. After making predictions, they compare their results to the correct answers. If they get it wrong, they adjust their understanding to do better next time.\\n\\n4. **Generalization**: A good AI model doesn’t just memorize the examples it sees; it learns to generalize from them. This means it can make accurate predictions on new, unseen data that it hasn’t encountered before.\\n\\n5. **Overfitting and Underfitting**: \\n   - **Overfitting** happens when a model learns too much from the training data, including noise and outliers, making it perform poorly on new data.\\n   - **Underfitting** occurs when a model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and new data.\\n\\n6. **Optimization**: AI models often use optimization techniques to improve their performance. This involves adjusting the model's parameters to minimize errors in predictions.\\n\\n7. **Transfer Learning**: Sometimes, a model trained on one task can be adapted to perform well on a different but related task. This is called transfer learning and helps save time and resources.\\n\\n8. **Continuous Learning**: Some AI models can continue to learn and improve over time as they receive new data. This allows them to adapt to changes in the environment or user preferences.\\n\\n9. **Evaluation**: To know how well an AI model is performing, it needs to be evaluated using metrics. This helps determine if the model is learning effectively and where it might need improvement.\\n\\nIn summary, the principles of learning in AI models revolve around using data to learn patterns, improving through feedback, generalizing to new situations, and continuously optimizing performance.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the invoke method of the chain object to pass the input\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the basic ideas that guide how AI systems learn from data and improve their performance over time. Here are some key principles explained in simple terms:\n",
      "\n",
      "1. **Data is Key**: AI models learn from data. The more quality data they have, the better they can learn. Think of it like a student studying for a test; the more information they have, the better they can prepare.\n",
      "\n",
      "2. **Learning from Examples**: AI models learn by looking at examples. For instance, if you want an AI to recognize cats in pictures, you show it many pictures of cats and non-cats. Over time, it learns to identify the features that make a cat a cat.\n",
      "\n",
      "3. **Feedback Loop**: AI models often use feedback to improve. After making a prediction (like guessing if a picture has a cat), they check if they were right or wrong. This feedback helps them adjust and make better guesses in the future.\n",
      "\n",
      "4. **Generalization**: A good AI model doesn’t just memorize the examples it sees; it learns to generalize. This means it can apply what it learned to new, unseen examples. For instance, if it learns about cats from specific pictures, it should still recognize a different cat in a new picture.\n",
      "\n",
      "5. **Overfitting and Underfitting**: These are two common problems in learning. Overfitting happens when a model learns too much from the training data, including noise and outliers, making it perform poorly on new data. Underfitting occurs when a model doesn’t learn enough from the data, leading to poor performance on both training and new data. The goal is to find a balance.\n",
      "\n",
      "6. **Continuous Improvement**: AI models can keep learning and improving over time. This is similar to how people learn from experience. The more they practice and get feedback, the better they become.\n",
      "\n",
      "7. **Transfer Learning**: Sometimes, models can use knowledge gained from one task to help with another related task. For example, if an AI learns to recognize dogs, it might use that knowledge to help recognize other animals.\n",
      "\n",
      "8. **Exploration vs. Exploitation**: In some learning scenarios, especially in reinforcement learning, models must balance exploring new strategies (trying new things) and exploiting known strategies (using what they already know works well). This is like trying new recipes while also sticking to your favorite ones.\n",
      "\n",
      "These principles help guide the development and training of AI models, ensuring they learn effectively and can perform well in various tasks."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying and Modifying Templates\n",
    "\n",
    "- The prompt content below can be **modified** as needed for testing purposes.  \n",
    "- The `model_name` can also be adjusted for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a seasoned English teacher with 10 years of experience. Please write an English conversation suitable for the given situation.  \n",
    "Refer to the [FORMAT] for the structure.\n",
    "\n",
    "#SITUATION:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- Dialogue in English:\n",
    "- Explanation of the Dialogue: \n",
    "\"\"\"\n",
    "\n",
    "# Generate the prompt using the PromptTemplate\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize the ChatOpenAI model.\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Initialize the string output parser.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the chain.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Dialogue in English:**\n",
      "\n",
      "**Waiter:** Good evening! Welcome to Bella Italia. How many are in your party?  \n",
      "**You:** Just one, please.  \n",
      "**Waiter:** Right this way. Here’s your menu. Can I get you something to drink while you look it over?  \n",
      "**You:** Yes, I’d like a glass of water, please.  \n",
      "**Waiter:** Sure! I’ll be right back with that.  \n",
      "**You:** Thank you!  \n",
      "**(After a few minutes)**  \n",
      "**Waiter:** Are you ready to order?  \n",
      "**You:** Yes, I’d like the spaghetti carbonara, please.  \n",
      "**Waiter:** Great choice! Would you like any appetizers or dessert with that?  \n",
      "**You:** I’ll have a side salad as an appetizer, but no dessert for me today.  \n",
      "**Waiter:** Perfect! I’ll get that order in for you.  \n",
      "**You:** Thank you!  \n",
      "**Waiter:** You’re welcome. Enjoy your meal!\n",
      "\n",
      "- **Explanation of the Dialogue:**\n",
      "In this conversation, the exchange takes place in a restaurant setting where the customer is being greeted by the waiter. The dialogue begins with a warm welcome and inquiry about the number of guests. The customer indicates they are dining alone and is provided with a menu. The waiter offers a drink, and the customer requests water, showing polite interaction.\n",
      "\n",
      "After giving the customer some time to review the menu, the waiter checks if they are ready to order. The customer confidently places an order for spaghetti carbonara and a side salad, demonstrating decision-making. The waiter suggests additional items, but the customer declines dessert, keeping the interaction straightforward. The waiter confirms the order and expresses a desire for the customer to enjoy their meal, reflecting good customer service. Overall, the dialogue illustrates a typical and courteous restaurant experience focused on ordering food.\n"
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response.\n",
    "print(chain.invoke({\"question\": \"I want to go to a restaurant and order food.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "**Customer:** Hi there! Can I see the menu, please?  \n",
      "**Waiter:** Of course! Here you go. Would you like any recommendations?  \n",
      "**Customer:** Yes, please. What do you recommend for a main dish?  \n",
      "**Waiter:** Our grilled salmon is very popular, and it's served with seasonal vegetables.  \n",
      "**Customer:** That sounds delicious! I’ll have the grilled salmon. Can I also get a side salad?  \n",
      "**Waiter:** Absolutely! What dressing would you like for your salad?  \n",
      "**Customer:** I'll have the balsamic vinaigrette, please.  \n",
      "**Waiter:** Great choice! Would you like anything to drink?  \n",
      "**Customer:** Yes, a glass of iced tea, please.  \n",
      "**Waiter:** Perfect! I’ll place your order now. It will be ready shortly.\n",
      "\n",
      "- Explanation of the Dialogue:\n",
      "In this conversation, the customer initiates the interaction by asking for the menu, indicating they are ready to order. The waiter responds promptly and offers assistance, showcasing good customer service. The customer seeks recommendations, allowing the waiter to suggest a popular dish, which helps guide their choice. The customer then specifies their order, including a side dish and drink, demonstrating clarity in communication. The waiter confirms the order and reassures the customer about the preparation time, creating a pleasant dining experience. This dialogue reflects common restaurant interactions, focusing on ordering food and communicating preferences effectively."
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response  \n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"I want to go to a restaurant and order food.\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "**Customer:** Hi there! I’d like to place an order for a pizza, please.\n",
      "\n",
      "**Pizza Shop Employee:** Sure! What size would you like? We have small, medium, large, and extra-large.\n",
      "\n",
      "**Customer:** I’ll go with a large, please. \n",
      "\n",
      "**Pizza Shop Employee:** Great choice! What toppings would you like on your pizza?\n",
      "\n",
      "**Customer:** Can I have pepperoni, mushrooms, and black olives?\n",
      "\n",
      "**Pizza Shop Employee:** Absolutely! Would you like any extra cheese or a special crust?\n",
      "\n",
      "**Customer:** Yes, I’d love extra cheese, and can I get a stuffed crust?\n",
      "\n",
      "**Pizza Shop Employee:** You got it! So that’s a large pizza with pepperoni, mushrooms, black olives, extra cheese, and stuffed crust. Would you like anything to drink?\n",
      "\n",
      "**Customer:** Yes, can I get a two-liter bottle of soda?\n",
      "\n",
      "**Pizza Shop Employee:** Sure! What kind of soda would you like?\n",
      "\n",
      "**Customer:** I'll take a cola, please.\n",
      "\n",
      "**Pizza Shop Employee:** Perfect! Your total comes to $25. Would you like to pick it up or have it delivered?\n",
      "\n",
      "**Customer:** I’ll pick it up. How long will it take?\n",
      "\n",
      "**Pizza Shop Employee:** It’ll be ready in about 20 minutes. \n",
      "\n",
      "**Customer:** Great, thank you!\n",
      "\n",
      "**Pizza Shop Employee:** Thank you! We’ll see you soon!\n",
      "\n",
      "- Explanation of the Dialogue: \n",
      "In this conversation, the customer initiates the order by greeting the pizza shop employee and expressing their desire to order a pizza. The employee responds by asking about the size of the pizza, prompting the customer to make a decision. The dialogue continues with the customer selecting toppings, cheese options, and crust type, showcasing a typical pizza ordering process. The employee also offers a drink option, allowing for a complete meal experience. The conversation concludes with the total cost and information about the pickup time, providing a clear and friendly exchange that illustrates a common interaction in a pizza shop setting. This conversation can be useful for students learning everyday English, particularly in a dining or food service context."
     ]
    }
   ],
   "source": [
    "# This time, set the question to 'Ordering Pizza in the US' and execute it.  \n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"Ordering Pizza in the US\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-i-KKkGhc-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
