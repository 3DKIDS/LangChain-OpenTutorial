{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example: Prompt+Model+OutputParser\n",
    "\n",
    "- Author: [ChangJun Lee](https://www.linkedin.com/in/cjleeno1/)\n",
    "- Design: []()\n",
    "- Peer Review: [Erika](https://github.com/ErikaPark)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The most fundamental and commonly used case involves linking a prompt template with a model. To illustrate how this works, let us create a chain that asks for the capital cities of various countries.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Utilizing Prompt Templates](#utilizing-prompt-templates)\n",
    "- [Chain Creation](#chain-creation)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain ChatOpenAI API reference](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n",
    "- [LangChain Core Output Parsers](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.list.CommaSeparatedListOutputParser.html#)\n",
    "- [Python List Tutorial](https://docs.python.org/3.13/tutorial/datastructures.html)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_community\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it. \n",
    "\n",
    "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration File for Managing API Key as an Environment Variable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API KEY Information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up LangSmith tracking: https://smith.langchain.com\n",
    "from langsmith import utils\n",
    "\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Prompt Templates\n",
    "\n",
    "`PromptTemplate`\n",
    "\n",
    "- A prompt template is used to create a complete prompt string by incorporating the user's input variables.\n",
    "- Usage\n",
    "  - `template`: A template string is a predefined format where curly braces '{}' are used to represent variables.\n",
    "\n",
    "  - `input_variables`: The names of the variables to be inserted within the curly braces are defined as a list.\n",
    "\n",
    "`input_variables`\n",
    "\n",
    "- `input_variables` is a list that defines the names of the variables used in the `PromptTemplate`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `from_template()` method is used to create a `PromptTemplate` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define template\n",
    "template = \"What is the capital of {country}?\"\n",
    "\n",
    "# Create a `PromptTemplate` object using the `from_template` method.\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Korea?'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"Korea\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of USA?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"USA\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Creation\n",
    "\n",
    "### LCEL (LangChain Expression Language)\n",
    "\n",
    "Here, we use LCEL to combine various components into a single chain.\n",
    "\n",
    "![lcel.png](./assets/lcel.png)\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "The `|` symbol works similarly to the [Unix pipe operator](<https://en.wikipedia.org/wiki/Pipeline_(Unix)>), linking different components and passing the output of one component as the input to the next.\n",
    "\n",
    "In this chain, user input is passed to the prompt template, and the output from the prompt template is then forwarded to the model. By examining each component individually, you can understand what happens at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt as a `PromptTemplate` object.\n",
    "prompt = PromptTemplate.from_template(\"Please explain {topic} in simple terms.\")\n",
    "\n",
    "\n",
    "# Combine the prompt and model into a chain\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling `invoke()`\n",
    "\n",
    "- Input values are provided in the form of a Python dictionary (key-value pairs).  \n",
    "- When calling the `invoke()` function, these input values are passed as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the topic in the `input` dictionary to 'The Principles of Learning in Artificial Intelligence Models'.\n",
    "input = {\"topic\": \"The Principles of Learning in Artificial Intelligence Models\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the basic ideas that guide how AI systems learn from data and improve their performance over time. Here are some key principles explained in simple terms:\\n\\n1. **Data is Key**: AI models learn from data. The more relevant and high-quality data they have, the better they can learn. Think of it like a student studying for a test; the more information they have, the better they can do.\\n\\n2. **Learning from Examples**: AI models often learn by looking at examples. For instance, if you want to teach an AI to recognize cats in pictures, you show it many pictures of cats and non-cats. Over time, it learns to identify the features that make a cat a cat.\\n\\n3. **Feedback Loop**: AI models improve through feedback. When they make predictions or decisions, they can receive feedback on whether they were right or wrong. This feedback helps them adjust and learn from their mistakes, similar to how a coach helps an athlete improve.\\n\\n4. **Generalization**: A good AI model can generalize from the examples it has seen to make predictions about new, unseen data. For example, if it has learned from pictures of various cats, it should be able to recognize a new cat it has never seen before.\\n\\n5. **Overfitting and Underfitting**: These are two common problems in learning. Overfitting happens when a model learns too much from the training data, including noise and outliers, making it perform poorly on new data. Underfitting occurs when a model doesn’t learn enough from the data, leading to poor performance on both training and new data. The goal is to find a balance.\\n\\n6. **Continuous Learning**: AI models can continue to learn and adapt over time. This means they can improve as they are exposed to more data or as the environment changes, much like how people keep learning throughout their lives.\\n\\n7. **Algorithms Matter**: The methods or algorithms used to train AI models are crucial. Different algorithms can lead to different learning outcomes, just like different teaching methods can affect how well students learn.\\n\\n8. **Evaluation and Testing**: To know how well an AI model is learning, it needs to be tested on separate data that it hasn’t seen before. This helps to evaluate its performance and ensure it’s not just memorizing the training data.\\n\\nIn summary, the principles of learning in AI models revolve around using data effectively, learning from examples, receiving feedback, generalizing knowledge, avoiding common pitfalls, and continuously improving. These principles help create AI systems that can perform tasks intelligently and adapt to new challenges.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 542, 'prompt_tokens': 21, 'total_tokens': 563, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-a8957cb0-2552-42ed-8e81-695f6cd397bd-0', usage_metadata={'input_tokens': 21, 'output_tokens': 542, 'total_tokens': 563, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the `prompt` object and the `model` object using the pipe (`|`) operator.  \n",
    "# Use the `invoke` method to pass the `input`.  \n",
    "# This will return the message generated by the AI model.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of outputting a streaming response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The principles of learning in artificial intelligence (AI) models can be understood as the basic ideas that guide how these models learn from data. Here are some key principles explained in simple terms:\n",
      "\n",
      "1. **Data is Key**: AI models learn from data. The more relevant and high-quality data you provide, the better the model can learn and make predictions.\n",
      "\n",
      "2. **Learning from Examples**: AI models often learn by looking at examples. For instance, if you want a model to recognize cats in pictures, you show it many pictures of cats and non-cats. The model learns to identify patterns that distinguish cats from other objects.\n",
      "\n",
      "3. **Feedback Loop**: Many AI models use a feedback mechanism. After making a prediction, they compare it to the correct answer. If they get it wrong, they adjust their internal settings to improve future predictions. This is similar to how we learn from our mistakes.\n",
      "\n",
      "4. **Generalization**: A good AI model doesn’t just memorize the examples it sees; it learns to generalize from them. This means it can make accurate predictions on new, unseen data that it hasn’t encountered before.\n",
      "\n",
      "5. **Overfitting and Underfitting**: \n",
      "   - **Overfitting** happens when a model learns too much from the training data, including noise and outliers, making it perform poorly on new data.\n",
      "   - **Underfitting** occurs when a model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and new data. The goal is to find a balance between the two.\n",
      "\n",
      "6. **Iterative Improvement**: Learning is often an iterative process. Models are trained in cycles, where they continuously improve their performance through repeated exposure to data and adjustments based on feedback.\n",
      "\n",
      "7. **Feature Importance**: AI models learn to identify which aspects (or features) of the data are most important for making predictions. For example, in recognizing a cat, features like fur patterns, ear shape, and whiskers might be important.\n",
      "\n",
      "8. **Transfer Learning**: Sometimes, models can leverage knowledge gained from one task to help with another related task. This is called transfer learning and can save time and resources.\n",
      "\n",
      "9. **Exploration vs. Exploitation**: In some learning scenarios, especially in reinforcement learning, models must balance exploring new strategies (exploration) and using known strategies that work well (exploitation).\n",
      "\n",
      "10. **Continuous Learning**: AI models can continue to learn and adapt over time as they receive new data. This helps them stay relevant and improve their accuracy.\n",
      "\n",
      "In summary, the principles of learning in AI models revolve around using data effectively, learning from examples, adjusting based on feedback, and striving for a balance between memorizing and generalizing. These principles help AI systems become more accurate and useful in various applications."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "\n",
    "An **Output Parser** is a tool designed to transform or process the responses from an AI model into a specific format. Since the model's output is typically provided as free-form text, an **Output Parser** is essential to convert it into a structured format or extract the required data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser() # Directly returns the model's response as a string without modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An output parser is added to the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A processing chain is constructed by connecting the prompt, model, and output parser.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the basic ideas that guide how AI systems learn from data and improve their performance over time. Here are some key principles explained in simple terms:\\n\\n1. **Data Input**: AI models learn from data. The more relevant and high-quality data they receive, the better they can learn. Think of it like a student studying from a good textbook.\\n\\n2. **Patterns Recognition**: AI looks for patterns in the data. Just like humans recognize faces or voices, AI identifies trends and relationships in the information it processes.\\n\\n3. **Feedback Loop**: AI models often use feedback to improve. When they make predictions or decisions, they can receive feedback on whether they were right or wrong. This is similar to a teacher correcting a student’s mistakes.\\n\\n4. **Generalization**: After learning from specific examples, AI models try to apply what they’ve learned to new, unseen data. This is like a student who learns math concepts and can solve different problems using the same principles.\\n\\n5. **Iteration**: Learning is an ongoing process. AI models can be trained multiple times, refining their understanding and improving their accuracy with each iteration, much like how practice helps a student get better at a subject.\\n\\n6. **Overfitting and Underfitting**: AI models can sometimes learn too much from the training data (overfitting), making them less effective on new data. Conversely, if they don’t learn enough (underfitting), they won’t perform well either. It’s like a student who memorizes answers without understanding the material.\\n\\n7. **Transfer Learning**: Sometimes, knowledge gained from one task can help with another related task. This is similar to how learning a new language can be easier if you already know another one.\\n\\n8. **Exploration vs. Exploitation**: AI models need to balance exploring new strategies (trying new things) and exploiting known strategies (using what they already know works). This is like a student trying different study methods to see which one helps them learn best.\\n\\n9. **Scalability**: AI models should be able to handle increasing amounts of data and complexity without losing performance. This is like a student who can manage more subjects as they progress in their education.\\n\\n10. **Ethics and Fairness**: AI should be designed to make fair and unbiased decisions. This principle emphasizes the importance of teaching AI to treat all data and individuals fairly, similar to how a good teacher treats all students equally.\\n\\nThese principles help guide the development and training of AI models, ensuring they learn effectively and can be applied to real-world problems.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the invoke method of the chain object to pass the input\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The principles of learning in artificial intelligence (AI) models can be understood as the basic ideas that guide how these models learn from data. Here are some key principles explained in simple terms:\n",
      "\n",
      "1. **Data is Key**: AI models learn from data. The more relevant and high-quality data you provide, the better the model can learn. Think of it like teaching a child; the more books and experiences they have, the more they learn.\n",
      "\n",
      "2. **Patterns and Features**: AI looks for patterns in the data. It identifies important features (characteristics) that help it understand and make predictions. For example, if you're teaching an AI to recognize cats, it will learn features like fur texture, ear shape, and eye color.\n",
      "\n",
      "3. **Feedback Loop**: Learning involves feedback. When an AI makes a prediction, it gets feedback on whether it was right or wrong. This helps the model adjust and improve over time, similar to how a student learns from their mistakes.\n",
      "\n",
      "4. **Generalization**: A good AI model can generalize from the data it has seen to make predictions about new, unseen data. This means it can apply what it learned in one situation to different but related situations.\n",
      "\n",
      "5. **Overfitting and Underfitting**: These are common problems in learning. Overfitting happens when a model learns too much from the training data, including noise and outliers, making it perform poorly on new data. Underfitting occurs when a model is too simple to capture the underlying patterns in the data. The goal is to find a balance.\n",
      "\n",
      "6. **Learning Algorithms**: Different algorithms (methods) are used for learning. Some are better for certain types of data or tasks. For example, neural networks are great for image recognition, while decision trees might work better for simpler classification tasks.\n",
      "\n",
      "7. **Iteration**: Learning is often an iterative process. Models are trained, tested, and refined multiple times to improve their performance. This is like practicing a skill repeatedly until you get better at it.\n",
      "\n",
      "8. **Transfer Learning**: Sometimes, models can use knowledge gained from one task to help with another related task. This is called transfer learning and can save time and resources.\n",
      "\n",
      "9. **Ethics and Bias**: AI models can learn biases present in the data. It's important to ensure that the data is fair and representative to avoid perpetuating stereotypes or making unfair decisions.\n",
      "\n",
      "In summary, the principles of learning in AI models revolve around using data to find patterns, receiving feedback to improve, and ensuring that the model can generalize its learning to new situations while being mindful of potential biases."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying and Modifying Templates\n",
    "\n",
    "- The prompt content below can be **modified** as needed for testing purposes.  \n",
    "- The `model_name` can also be adjusted for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a seasoned English teacher with 10 years of experience. Please write an English conversation suitable for the given situation.  \n",
    "Refer to the [FORMAT] for the structure.\n",
    "\n",
    "#SITUATION:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- Dialogue in English:\n",
    "- Explanation of the Dialogue: \n",
    "\"\"\"\n",
    "\n",
    "# Generate the prompt using the PromptTemplate\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize the ChatOpenAI model.\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Initialize the string output parser.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the chain.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "**Waiter:** Good evening! Welcome to Bella Italia. How many people are in your party?  \n",
      "**You:** Hi! Just one, please.  \n",
      "**Waiter:** Right this way. Here’s your menu. Can I start you off with something to drink?  \n",
      "**You:** Yes, I’d like a sparkling water, please.  \n",
      "**Waiter:** Great choice! Are you ready to order, or do you need a few more minutes?  \n",
      "**You:** I think I’m ready. I’ll have the spaghetti carbonara, please.  \n",
      "**Waiter:** Excellent choice! Would you like to add a side salad with that?  \n",
      "**You:** Yes, that sounds good. I’ll take the house salad.  \n",
      "**Waiter:** Perfect! I’ll get that order in for you. Is there anything else you need?  \n",
      "**You:** No, that will be all for now, thank you!  \n",
      "**Waiter:** You’re welcome! I’ll be back with your drink shortly.  \n",
      "\n",
      "- Explanation of the Dialogue:  \n",
      "In this conversation, you are at a restaurant and interact with the waiter. The dialogue begins with the waiter greeting you and asking how many people are in your party. You indicate that you're dining alone. The waiter then guides you to your seat and presents the menu, offering to take your drink order first. You choose sparkling water, which is a common beverage option. After that, the waiter checks if you are ready to order food. You confirm that you are ready and order spaghetti carbonara, which is a pasta dish. The waiter offers an additional side salad, and you agree to that as well. Finally, you confirm that you don’t need anything else, and the waiter assures you they will return soon with your drink. This conversation emphasizes polite interactions in a restaurant setting, demonstrating how to order food and drinks while engaging in friendly small talk with the staff.\n"
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response.\n",
    "print(chain.invoke({\"question\": \"I want to go to a restaurant and order food.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "\n",
      "**Waiter:** Good evening! Welcome to Bella’s Bistro. How many are in your party tonight?\n",
      "\n",
      "**Customer:** Good evening! It’s just me, please. Could I have a table for one?\n",
      "\n",
      "**Waiter:** Of course! Right this way. Here’s the menu. Can I start you off with something to drink?\n",
      "\n",
      "**Customer:** Yes, please. I’d like a glass of water and a glass of red wine.\n",
      "\n",
      "**Waiter:** Great choice! I’ll be right back with your drinks. Have you had a chance to look at the menu?\n",
      "\n",
      "**Customer:** Yes, I have. I think I’ll have the grilled salmon with asparagus, please.\n",
      "\n",
      "**Waiter:** Excellent choice! Would you like any appetizers with that?\n",
      "\n",
      "**Customer:** Hmm, I’ll try the bruschetta, please.\n",
      "\n",
      "**Waiter:** Perfect! I’ll get that order in for you. Is there anything else I can bring you?\n",
      "\n",
      "**Customer:** No, that will be all for now, thank you.\n",
      "\n",
      "**Waiter:** You’re welcome! I’ll be back shortly with your drinks and food.\n",
      "\n",
      "---\n",
      "\n",
      "- Explanation of the Dialogue: \n",
      "\n",
      "In this dialogue, the customer is at a restaurant and interacts with the waiter to order food and drinks. The conversation starts with a greeting and a request for a table, which sets a polite and friendly tone. The waiter offers the menu and asks if the customer would like a drink, showing attentiveness to the customer's needs. The customer orders a drink and a meal, and the waiter follows up by suggesting appetizers, demonstrating good service. The dialogue ends with the waiter confirming the order and assuring the customer that their food and drinks will be brought shortly. This conversation reflects a common restaurant scenario, emphasizing courtesy and clarity in communication."
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response  \n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"I want to go to a restaurant and order food.\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "**Customer:** Hi there! I’d like to order a pizza, please.  \n",
      "**Pizza Place:** Sure! What size would you like?  \n",
      "**Customer:** I’ll have a large, please.  \n",
      "**Pizza Place:** Great choice! What toppings do you want?  \n",
      "**Customer:** Can I get pepperoni, mushrooms, and extra cheese?  \n",
      "**Pizza Place:** Absolutely! Would you like anything else?  \n",
      "**Customer:** Yes, could I also get a side of garlic bread?  \n",
      "**Pizza Place:** Of course! That will be $25. Would you like to pick it up or have it delivered?  \n",
      "**Customer:** I’ll have it delivered, please.  \n",
      "**Pizza Place:** No problem. Can I have your address?  \n",
      "**Customer:** Sure! It’s 123 Maple Street.  \n",
      "**Pizza Place:** Thank you! Your order will be there in about 30 minutes.  \n",
      "**Customer:** Perfect, thanks so much!  \n",
      "\n",
      "- Explanation of the Dialogue: \n",
      "In this conversation, the customer is placing an order for a pizza at a pizzeria. The interaction starts with the customer greeting the staff and expressing the desire to order. The staff begins by asking for the size of the pizza, which leads to the customer selecting a large pizza. The dialogue continues with the customer specifying the toppings, which is a common practice when ordering pizza. After the toppings are confirmed, the staff inquires if the customer would like anything else, to which the customer adds garlic bread. The staff then informs the customer of the total cost and asks for the delivery preference. The customer opts for delivery and provides their address. Finally, the staff gives an estimated delivery time, concluding the conversation on a positive note. This dialogue highlights key phrases and vocabulary used in everyday pizza ordering situations in the U.S."
     ]
    }
   ],
   "source": [
    "# This time, set the question to 'Ordering Pizza in the US' and execute it.  \n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"Ordering Pizza in the US\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-i-KKkGhc-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
