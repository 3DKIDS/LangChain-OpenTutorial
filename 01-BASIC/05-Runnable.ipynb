{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "635d8ebb",
   "metadata": {},
   "source": [
    "# Runnable\n",
    "\n",
    "- Author: [hyeyeoon](https://github.com/hyeyeoon)\n",
    "- Design: []()\n",
    "- Peer Review: []()\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "LangChain's `Runnable` objects provide a modular and flexible approach to designing workflows by enabling the chaining, parallel execution, and transformation of data. These utilities allow for efficient handling of structured inputs and outputs, with minimal code overhead.\n",
    "\n",
    "### Key Components:\n",
    "\n",
    "- **`RunnableLambda`**: A lightweight utility that enables the application of custom logic through lambda functions, ideal for dynamic and quick data transformations.\n",
    "- **`RunnablePassthrough`**: Designed to pass input data unchanged or augment it with additional attributes when paired with the `.assign()` method.\n",
    "- **`itemgetter`**: A Python `operator` module utility for efficiently extracting specific keys or indices from structured data such as dictionaries or tuples.\n",
    "\n",
    "These tools can be combined to build powerful workflows, such as:\n",
    "\n",
    "1. Extracting and processing specific data elements using `itemgetter`.\n",
    "2. Performing custom transformations with `RunnableLambda`.\n",
    "3. Creating end-to-end data pipelines with `Runnable` chains.\n",
    "\n",
    "By leveraging these components, users can design scalable and reusable pipelines for machine learning and data processing workflows.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Efficient Data Handling with RunnablePassthrough](#efficient-data-handling-with-runnablepassthrough)\n",
    "- [Efficient Parallel Execution with RunnableParallel](#efficient-parallel-execution-with-runnableparallel)\n",
    "- [Dynamic Processing with RunnableLambda](#dynamic-processing-with-runnablelambda)\n",
    "- [Extracting Specific Keys Using itemgetter](#extracting-specific-keys-using-itemgetter)\n",
    "\n",
    "---\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain Documentation: Runnable](https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.base.Runnable.html)\n",
    "- [LangChain Documentation](https://python.langchain.com/docs/how_to/lcel_cheatsheet/)\n",
    "- [Python operator module: itemgetter](https://docs.python.org/3/library/operator.html#operator.itemgetter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c7aba4",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21943adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "!pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f25ec196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_openai\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f9065ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"05-Runnable\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a9ae0",
   "metadata": {},
   "source": [
    "You can also load the `OPEN_API_KEY` from the `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f99b5b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa00c3f4",
   "metadata": {},
   "source": [
    "## Efficient Data Handling with RunnablePassthrough\n",
    "\n",
    "`RunnablePassthrough` is a utility designed to streamline data processing workflows by either passing input data unchanged or enhancing it with additional attributes. Its flexibility makes it a valuable tool for handling data in pipelines where minimal transformation or selective augmentation is required.\n",
    "\n",
    "1. **Simple Data Forwarding**\n",
    "\n",
    "- Suitable for scenarios where no transformation is required, such as logging raw data or passing it to downstream systems.\n",
    "\n",
    "2. **Dynamic Data Augmentation**\n",
    "\n",
    "- Enables the addition of metadata or context to input data for use in machine learning pipelines or analytics systems.\n",
    "\n",
    "---\n",
    "- `RunnablePassthrough` can either pass the input unchanged or append additional keys to it.\n",
    "- When `RunnablePassthrough()` is called on its own, it simply takes the input and passes it as is.\n",
    "- When called using `RunnablePassthrough.assign(...)`, it takes the input and adds additional arguments provided to the assign function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d4cfa6",
   "metadata": {},
   "source": [
    "### RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69cb77da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create the prompt and llm\n",
    "prompt = PromptTemplate.from_template(\"What is 10 times {num}?\")\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create the chain\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadbd932",
   "metadata": {},
   "source": [
    "When invoking the chain with `invoke()`, the input data must be of type `dictionary`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d367787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10 times 5 is equal to 50.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 15, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-eb423b33-7959-4387-83e3-b64e078aaa18-0', usage_metadata={'input_tokens': 15, 'output_tokens': 11, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the chain\n",
    "chain.invoke({\"num\": 5})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac736fc2",
   "metadata": {},
   "source": [
    "However, with the update to the LangChain library, if the template includes **only one variable**, it is also possible to pass just the value directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a2b5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10 times 5 is equal to 50.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 15, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d9744b8d-df02-426e-9635-3f793e87ca5f-0', usage_metadata={'input_tokens': 15, 'output_tokens': 11, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the chain\n",
    "chain.invoke(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8017f7",
   "metadata": {},
   "source": [
    "Here is an example using `RunnablePassthrough`.\n",
    "\n",
    "`RunnablePassthrough` is a `runnable` object, and `runnable` objects can be executed independently using the `invoke()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b93e0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Runnable\n",
    "RunnablePassthrough().invoke({\"num\": 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a77202f",
   "metadata": {},
   "source": [
    "Here is an example of creating a chain using `RunnablePassthrough`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ade3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='10 times 10 is equal to 100.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 15, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-97368725-4381-4b22-b419-e1f30366b619-0', usage_metadata={'input_tokens': 15, 'output_tokens': 11, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable_chain = {\"num\": RunnablePassthrough()} | prompt | ChatOpenAI()\n",
    "\n",
    "# The dict value has been updated with RunnablePassthrough().\n",
    "runnable_chain.invoke(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b96bc8",
   "metadata": {},
   "source": [
    "Here is a comparison of the results when using `RunnablePassthrough.assign()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5baf9b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RunnablePassthrough().invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d0e32b",
   "metadata": {},
   "source": [
    "`RunnablePassthrough.assign()`\n",
    "- Combines the key/value pairs from the input with the newly assigned key/value pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00bd941c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num': 1, 'new_num': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input key: num, Assigned key: new_num\n",
    "(RunnablePassthrough.assign(new_num=lambda x: x[\"num\"] * 3)).invoke({\"num\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13370494",
   "metadata": {},
   "source": [
    "## Efficient Parallel Execution with RunnableParallel\n",
    "\n",
    "`RunnableParallel` is a utility designed to execute multiple `Runnable` objects concurrently, streamlining workflows that require parallel processing. It distributes input data across different components, collects their results, and combines them into a unified output. This functionality makes it a powerful tool for optimizing workflows where tasks can be performed independently and simultaneously.\n",
    "\n",
    "\n",
    "1. **Concurrent Execution**\n",
    "   - Executes multiple `Runnable` objects simultaneously, reducing the time required for tasks that can be parallelized.\n",
    "\n",
    "2. **Unified Output Management**\n",
    "   - Combines the results from all parallel executions into a single, cohesive output, simplifying downstream processing.\n",
    "\n",
    "3. **Flexibility**\n",
    "   - Can handle diverse input types and support complex workflows by distributing the workload efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "929d398b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'passed': {'num': 1}, 'extra': {'num': 1, 'mult': 3}, 'modified': 2}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Create an instance of RunnableParallel. This instance allows multiple Runnable objects to be executed in parallel.\n",
    "runnable = RunnableParallel(\n",
    "    # Pass a RunnablePassthrough instance as the 'passed' keyword argument. This simply passes the input data through without modification.\n",
    "    passed=RunnablePassthrough(),\n",
    "    # Use RunnablePassthrough.assign as the 'extra' keyword argument to assign a lambda function 'mult'. \n",
    "    # This function multiplies the value associated with the 'num' key in the input dictionary by 3.\n",
    "    extra=RunnablePassthrough.assign(mult=lambda x: x[\"num\"] * 3),\n",
    "    # Pass a lambda function as the 'modified' keyword argument. \n",
    "    # This function adds 1 to the value associated with the 'num' key in the input dictionary.\n",
    "    modified=lambda x: x[\"num\"] + 1,\n",
    ")\n",
    "\n",
    "# Call the invoke method on the runnable instance, passing a dictionary {'num': 1} as input.\n",
    "runnable.invoke({\"num\": 1})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27516f65",
   "metadata": {},
   "source": [
    "Chains can also be applied to RunnableParallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "873c5f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain1 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"What is the capital of {country}?\")\n",
    "    | ChatOpenAI()\n",
    ")\n",
    "chain2 = (\n",
    "    {\"country\": RunnablePassthrough()}\n",
    "    | PromptTemplate.from_template(\"What is the area of {country}?\")\n",
    "    | ChatOpenAI()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92dc30d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'capital': AIMessage(content='The capital of South Korea is Seoul.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 15, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-d22e9120-193c-4a66-9d3b-3d39d4ba4b31-0', usage_metadata={'input_tokens': 15, 'output_tokens': 9, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " 'area': AIMessage(content='The total area of South Korea is approximately 100,363 square kilometers.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 15, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-545af851-6b22-4c2c-9b5f-b0c54aad405f-0', usage_metadata={'input_tokens': 15, 'output_tokens': 16, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_chain = RunnableParallel(capital=chain1, area=chain2)\n",
    "combined_chain.invoke(\"South Korea\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982775c8",
   "metadata": {},
   "source": [
    "## Dynamic Processing with RunnableLambda\n",
    "\n",
    "`RunnableLambda` is a flexible utility that allows developers to define custom data transformation logic using lambda functions. By enabling quick and easy implementation of custom processing workflows, `RunnableLambda` simplifies the creation of tailored data pipelines while ensuring minimal setup overhead.\n",
    "\n",
    "1. **Customizable Data Transformation**\n",
    "   - Allows users to define custom logic for transforming input data using lambda functions, offering unparalleled flexibility.\n",
    "\n",
    "2. **Lightweight and Simple**\n",
    "   - Provides a straightforward way to implement ad-hoc processing without the need for extensive class or function definitions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa9fc167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jan-01'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_today(a):\n",
    "    # Get today's date\n",
    "    return datetime.today().strftime(\"%b-%d\")\n",
    "\n",
    "\n",
    "# Print today's date\n",
    "get_today(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3247ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# Create the prompt and llm\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"List {n} famous people whose birthday is on {today}. Include their date of birth.\"\n",
    ")\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# Create the chain\n",
    "chain = (\n",
    "    {\"today\": RunnableLambda(get_today), \"n\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c5ba7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three famous people born on January 1:\n",
      "\n",
      "1. **Paul Revere** - Born on January 1, 1735. He was an American silversmith and a patriot in the American Revolution, best known for his midnight ride to alert the colonial militia of the approaching British forces.\n",
      "\n",
      "2. **J. Edgar Hoover** - Born on January 1, 1895. He was the first Director of the Federal Bureau of Investigation (FBI) of the United States and served from 1924 until his death in 1972.\n",
      "\n",
      "3. **Verne Troyer** - Born on January 1, 1969. He was an American actor and comedian, best known for his role as Mini-Me in the \"Austin Powers\" film series.\n"
     ]
    }
   ],
   "source": [
    "# Output\n",
    "print(chain.invoke(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564e7c3f",
   "metadata": {},
   "source": [
    "## Extracting Specific Keys Using `itemgetter`\n",
    "\n",
    "`itemgetter` is a utility function provided by Python's `operator` module that helps efficiently extract specific keys or indices from dictionaries, tuples, or lists. It is particularly useful when working with structured data and requires extracting specific elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af3c8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "# Function that returns the length of a sentence.\n",
    "def length_function(text):\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "# Function that returns the product of the lengths of two sentences.\n",
    "def _multiple_length_function(text1, text2):\n",
    "    return len(text1) * len(text2)\n",
    "\n",
    "\n",
    "# Function that uses _multiple_length_function to return the product of the lengths of two sentences.\n",
    "def multiple_length_function(_dict):\n",
    "    return _multiple_length_function(_dict[\"text1\"], _dict[\"text2\"])\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is {a} + {b}?\")\n",
    "model = ChatOpenAI()\n",
    "\n",
    "chain1 = prompt | model\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"a\": itemgetter(\"word1\") | RunnableLambda(length_function),\n",
    "        \"b\": {\"text1\": itemgetter(\"word1\"), \"text2\": itemgetter(\"word2\")}\n",
    "        | RunnableLambda(multiple_length_function),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31d8f148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='5 + 25 = 30', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 15, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8d96df30-99e7-49a1-a4ce-2cdcadf3ac9f-0', usage_metadata={'input_tokens': 15, 'output_tokens': 8, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"word1\": \"hello\", \"word2\": \"world\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-6Qq4Ubg1-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
