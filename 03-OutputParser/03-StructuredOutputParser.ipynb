{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Structured Output Parser\n",
        "\n",
        "- Author: [Yoolim Han](https://github.com/hohosznta)\n",
        "- Design: []()\n",
        "- Peer Review: []()\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
        "\n",
        "## Overview\n",
        "\n",
        "The `StructuredOutputParser` is a valuable tool for formatting Large Language Model (LLM) responses into dictionary structures, enabling the return of multiple fields as key/value pairs. \n",
        "hile Pydantic and JSON parsers offer robust capabilities, the `StructuredOutputParser `is particularly effective for less powerful models, such as local models with fewer parameters. It is especially beneficial for models with lower intelligence compared to advanced models like GPT or Claude. \n",
        "By utilizing the `StructuredOutputParser`, developers can maintain data integrity and consistency across various LLM applications, even when operating with models that have reduced parameter counts.\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Implementing Structured Output Parser](#implementing-structured-output-parser)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain ChatOpenAI API reference](https://python.langchain.com/docs/integrations/chat/openai/)\n",
        "- [LangChain Structured output parser](https://python.langchain.com/docs/how_to/output_parser_structured/)\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'DOSKEY'��(��) ���� �Ǵ� �ܺ� ����, ������ �� �ִ� ���α׷�, �Ǵ�\n",
            "��ġ ������ �ƴմϴ�.\n"
          ]
        }
      ],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_openai\",\n",
        "        \"langchain_community\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"03-StructuredOutputParser\",\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it. \n",
        "\n",
        "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementing Structured Output Parser"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jJN9mDnR2Mp"
      },
      "source": [
        "### Using ResponseSchema with StructuredOutputParser\n",
        "*   Define a response schema using the ResponseSchema class to include the answer to the user's question and a description of the source (website) used.\n",
        "\n",
        "*   Initialize `StructuredOutputParser` with response_schemas to structure the output according to the defined response schema.\n",
        "\n",
        "**[Note]**\n",
        "When using local models, Pydantic parsers may frequently fail to work properly. In such cases, using `StructuredOutputParser` can be a good alternative solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "udCLc1sDR01b"
      },
      "outputs": [],
      "source": [
        "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
        "\n",
        "# Response to the user's question\n",
        "response_schemas = [\n",
        "    ResponseSchema(name=\"answer\", description=\"Answer to the user's question\"),\n",
        "    ResponseSchema(\n",
        "        name=\"source\",\n",
        "        description=\"The `source` used to answer the user's question, which should be a `website URL`.\",\n",
        "    ),\n",
        "]\n",
        "# Initialize the structured output parser based on the response schemas\n",
        "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMgOch7KTcNh"
      },
      "source": [
        "### Embedding Response Schemas into Prompts \n",
        "\n",
        "Create a PromptTemplate to format user questions and embed parsing instructions for structured outputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GeamtrixZMUJ"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "# Parse the format instructions.\n",
        "format_instructions = output_parser.get_format_instructions()\n",
        "prompt = PromptTemplate(\n",
        "    # Set up the template to answer the user's question as best as possible.\n",
        "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
        "    # Use 'question' as the input variable.\n",
        "    input_variables=[\"question\"],\n",
        "    # Use 'format_instructions' as a partial variable.\n",
        "    partial_variables={\"format_instructions\": format_instructions},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Integrating with ChatOpenAI and Running the Chain\n",
        "\n",
        "Combine the `PromptTemplate`, `ChatOpenAI` model, and `StructuredOutputParser` into a chain. Finally, run the chain with a specific `question` to produce results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSWnxIdOZRWy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\HP\\anaconda3\\envs\\llama3phidata\\Lib\\site-packages\\langsmith\\client.py:256: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
            "  warnings.warn(\n",
            "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c,id=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c; trace=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c,id=8eb08352-4d72-442b-9dad-274c9fda10e1\n",
            "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c,id=685effb4-a09b-4b4d-a5d6-e20e3473554f; trace=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c,id=8eb08352-4d72-442b-9dad-274c9fda10e1\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'answer': 'The largest desert in the world is the Antarctic Desert.',\n",
              " 'source': 'https://www.britannica.com/place/desert'}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI(temperature=0)  # Initialize the ChatOpenAI model\n",
        "\n",
        "chain = prompt | model | output_parser  # Connect the prompt, model, and output parser\n",
        "\n",
        "# What is the largest desert in the world?\n",
        "chain.invoke({\"question\": \"What is the largest desert in the world?\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IODAUdNHZZQ-"
      },
      "source": [
        "### Using Streamed Outputs\n",
        "\n",
        "Use the `chain.stream` method to receive a streaming response to the question, \"What are the achievements of King Sejong?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gzGhr-8DZaZu"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c,id=7489538d-e459-4594-a59c-c6e2ae5b7cb1; trace=b68f99d1-3b0e-4332-84d8-34e2ee45a689,id=b68f99d1-3b0e-4332-84d8-34e2ee45a689; trace=b68f99d1-3b0e-4332-84d8-34e2ee45a689,id=76c8bfe4-359f-45bc-9855-c37b7e5974d3; trace=b68f99d1-3b0e-4332-84d8-34e2ee45a689,id=c3635d6b-fbd0-412f-96c5-2ec496911075; trace=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c,id=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c; trace=ffe4d59c-bc75-4f4d-a5fc-5f85ccfe709c,id=685effb4-a09b-4b4d-a5d6-e20e3473554f\n",
            "Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=b68f99d1-3b0e-4332-84d8-34e2ee45a689,id=5e91491b-02e1-47f1-bd79-29fdd5578af6; trace=b68f99d1-3b0e-4332-84d8-34e2ee45a689,id=c3635d6b-fbd0-412f-96c5-2ec496911075; trace=b68f99d1-3b0e-4332-84d8-34e2ee45a689,id=b68f99d1-3b0e-4332-84d8-34e2ee45a689\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'answer': 'A standard soccer team consists of 11 players on the field at a time.', 'source': 'https://www.fifa.com/who-we-are/news/what-are-the-rules-of-football-2040008'}\n"
          ]
        }
      ],
      "source": [
        "for s in chain.stream({\"question\": \"How many players are on a soccer team?\"}):\n",
        "    # Stream the output\n",
        "    print(s)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llama3phidata",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
