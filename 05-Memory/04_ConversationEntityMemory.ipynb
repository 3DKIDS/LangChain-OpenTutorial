{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkf5OMA6kJax"
      },
      "source": [
        "# ConversationBufferWindowMemory\n",
        "\n",
        "- Author: [ulysyszh](https://github.com/ulysyszh)\n",
        "- Design: [ulysyszh](https://github.com/ulysyszh)\n",
        "- Peer Review: [Kenny Jung](https://www.linkedin.com/in/kwang-yong-jung)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/ulysyszh/LangChain-OpenTutorial/blob/main/05-Memory/04_ConversationEntityMemory.ipynb)\n",
        "\n",
        "\n",
        "## Overview\n",
        "\n",
        "`ConversationEntityMemory` allows the conversation system to retain facts about specific entities mentioned during the dialogue.\n",
        "\n",
        "In this case, Extracting information about entities from the conversation using a large language model.\n",
        "\n",
        "Accumulating knowledge about these entities over time using the same large language model.\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environement Setup](#environment-setup)\n",
        "- [Example](#example)\n",
        "- [Retrieving Entity Memory](#retrieving-entity-memory)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain Python API Reference > langchain: 0.3.13 > memory > ConversationEntityMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.entity.ConversationEntityMemory.html)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIebCeD3kJay"
      },
      "source": [
        "## Environment Setup\n",
        "Set up the environment to use ConversationEntityMemory.\n",
        "\n",
        "Installing Required Libraries\n",
        "Install the necessary dependencies using the langchain-opentutorial package:\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DD_gVCiEkJay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e89d6b-32bd-410a-d7cc-a5581710383f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain-opentutorial in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A7OJmbIOkJaz"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory.entity import ConversationEntityMemory\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "openai = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain-anthropic\",\n",
        "        \"langchain_community\",\n",
        "        \"langchain_text_splitters\",\n",
        "        \"langchain_openai\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "fqHKNkyjkJaz",
        "outputId": "754e71c8-b1d7-44ab-b246-8d9851a846fd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"ConversationEntityMemory\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AUOndzLpB30",
        "outputId": "dd82b1b9-a21a-4b70-faa3-516884796149"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UGWY4HXkJaz"
      },
      "source": [
        "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it.\n",
        "\n",
        "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "pFNkea-lkJa0",
        "outputId": "458730bb-d801-4e9d-c5aa-62a65e31c03b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{entities}\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Last line:\n",
            "Human: {input}\n",
            "You:\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n",
        "\n",
        "# Template output for verification. Currently there are no classes in the API, but the functionality works.\n",
        "print(ENTITY_MEMORY_CONVERSATION_TEMPLATE.template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SYhky2EkJa0"
      },
      "source": [
        "## Online Bank Account Opening Conversation Example\n",
        "\n",
        "This example demonstrates how to use `ConversationBufferWindowMemory` to simulate a virtual banking assistant conversation. The conversation flow shows a typical online bank account opening process, from initial greeting to account creation confirmation, while maintaining only the most recent interactions in memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "QBJ8r5NLkJa0"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=llm),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzw2XmW1kJa1"
      },
      "source": [
        "## Retrieving Conversation History\n",
        "\n",
        "Let's examine the conversation history stored in memory using the `load_memory_variables()` method to verify our window-based memory retention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "igqrJmNEkJa1",
        "outputId": "760f399b-f9fd-4e6e-aab0-7f8da1468303",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=ec0fad15-2a43-42c7-8118-c8a5cc77f1eb,id=ec0fad15-2a43-42c7-8118-c8a5cc77f1eb; trace=ec0fad15-2a43-42c7-8118-c8a5cc77f1eb,id=22e37e70-98b0-4a04-9ca4-3fe16d8f0570\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=1acc55e3-3c95-42ed-9a82-8bb0da771255,id=1acc55e3-3c95-42ed-9a82-8bb0da771255; trace=1acc55e3-3c95-42ed-9a82-8bb0da771255,id=24f299ff-22a8-47b8-b43a-d69325908436; trace=ec0fad15-2a43-42c7-8118-c8a5cc77f1eb,id=ec0fad15-2a43-42c7-8118-c8a5cc77f1eb; trace=ec0fad15-2a43-42c7-8118-c8a5cc77f1eb,id=22e37e70-98b0-4a04-9ca4-3fe16d8f0570\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=d51f1fca-bfc6-43a5-a952-0832820e6c1b,id=d51f1fca-bfc6-43a5-a952-0832820e6c1b; trace=d51f1fca-bfc6-43a5-a952-0832820e6c1b,id=81f8bb73-02ae-487a-8c58-15f895ddee05; trace=1acc55e3-3c95-42ed-9a82-8bb0da771255,id=24f299ff-22a8-47b8-b43a-d69325908436\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=37b0f41d-112e-4860-b155-9b657af4768f,id=37b0f41d-112e-4860-b155-9b657af4768f; trace=37b0f41d-112e-4860-b155-9b657af4768f,id=ac21800d-5166-4659-a145-c8398b746e2d; trace=d51f1fca-bfc6-43a5-a952-0832820e6c1b,id=d51f1fca-bfc6-43a5-a952-0832820e6c1b; trace=d51f1fca-bfc6-43a5-a952-0832820e6c1b,id=81f8bb73-02ae-487a-8c58-15f895ddee05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That sounds like a wonderful initiative! Combining the beauty of nature through photography with the important cause of wildlife conservation is a great way to raise awareness and support for endangered species. Amelia's expertise in landscape photography and David's dedication to wildlife conservation will surely make the gallery and learning center a success. If you need any assistance or advice on setting up the gallery or any other aspect of the project, feel free to ask!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=1acc55e3-3c95-42ed-9a82-8bb0da771255,id=1acc55e3-3c95-42ed-9a82-8bb0da771255; trace=37b0f41d-112e-4860-b155-9b657af4768f,id=37b0f41d-112e-4860-b155-9b657af4768f; trace=37b0f41d-112e-4860-b155-9b657af4768f,id=ac21800d-5166-4659-a145-c8398b746e2d\n"
          ]
        }
      ],
      "source": [
        "# Input conversation\n",
        "response = conversation.predict(\n",
        "    input=(\n",
        "        \"Amelia is an award-winning landscape photographer who has traveled around the globe capturing natural wonders. \"\n",
        "        \"David is a wildlife conservationist dedicated to protecting endangered species. \"\n",
        "        \"They are planning to open a nature-inspired photography gallery and learning center that raises funds for conservation projects.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Print the assistant's response\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the entity memory\n",
        "conversation.memory.entity_store.store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN98J2thEihi",
        "outputId": "0bf44e06-1d42-4077-90c2-5c6cf564b8d3"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Amelia': 'Amelia is an award-winning landscape photographer who has traveled around the globe capturing natural wonders.',\n",
              " 'David': 'David is a wildlife conservationist dedicated to protecting endangered species.'}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
