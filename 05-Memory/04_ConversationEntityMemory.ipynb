{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pkf5OMA6kJax"
      },
      "source": [
        "# ConversationEntityMemory\n",
        "\n",
        "- Author: [ulysyszh](https://github.com/ulysyszh)\n",
        "- Design: [ulysyszh](https://github.com/ulysyszh)\n",
        "- Peer Review: [Kenny Jung](https://www.linkedin.com/in/kwang-yong-jung)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://github.com/ulysyszh/LangChain-OpenTutorial/blob/main/05-Memory/04_ConversationEntityMemory.ipynb)\n",
        "\n",
        "\n",
        "## Overview\n",
        "\n",
        "`ConversationEntityMemory` allows the conversation system to retain facts about specific entities mentioned during the dialogue.\n",
        "\n",
        "In this case, Extracting information about entities from the conversation using a large language model.\n",
        "\n",
        "Accumulating knowledge about these entities over time using the same large language model.\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Conversation-Based Entity Memory Example](#Conversation-based-entity-memory-example)\n",
        "- [Retrieving Entity Memory](#retrieving-entity-memory)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain Python API Reference > langchain: 0.3.13 > memory > ConversationEntityMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.entity.ConversationEntityMemory.html)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIebCeD3kJay"
      },
      "source": [
        "## Environment Setup\n",
        "Set up the environment to use ConversationEntityMemory.\n",
        "\n",
        "Installing Required Libraries\n",
        "Install the necessary dependencies using the langchain-opentutorial package:\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DD_gVCiEkJay",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b32310b6-b5e2-475e-fd8c-280d77201478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: langchain-opentutorial in /usr/local/lib/python3.10/dist-packages (0.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.7.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.26->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-community langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "A7OJmbIOkJaz"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_community.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory.entity import ConversationEntityMemory\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "openai = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain-anthropic\",\n",
        "        \"langchain_community\",\n",
        "        \"langchain_text_splitters\",\n",
        "        \"langchain_openai\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "fqHKNkyjkJaz",
        "outputId": "f99fb39c-ceb2-46e9-9542-06a39f1731c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"ConversationEntityMemory\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AUOndzLpB30",
        "outputId": "66a5084a-98cb-4ce9-b189-25f82e87ee62"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UGWY4HXkJaz"
      },
      "source": [
        "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it.\n",
        "\n",
        "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "pFNkea-lkJa0",
        "outputId": "6d6584ca-6701-4c2d-c4ec-144c33e6f8d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['entities', 'history', 'input'] input_types={} partial_variables={} template='\\nYou are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou assist with various tasks, from answering simple questions to providing detailed discussions on a wide range of topics. You can generate human-like text, allowing natural conversations and coherent, relevant responses.\\n\\nYou constantly learn and improve, processing large amounts of text to provide accurate and informative responses. You can use personalized information provided in the context below, along with your own generated knowledge.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:\\n'\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "entity_memory_conversation_template = PromptTemplate(\n",
        "    input_variables=[\"entities\", \"history\", \"input\"],\n",
        "    template=\"\"\"\n",
        "You are an assistant to a human, powered by a large language model trained by OpenAI.\n",
        "\n",
        "You assist with various tasks, from answering simple questions to providing detailed discussions on a wide range of topics. You can generate human-like text, allowing natural conversations and coherent, relevant responses.\n",
        "\n",
        "You constantly learn and improve, processing large amounts of text to provide accurate and informative responses. You can use personalized information provided in the context below, along with your own generated knowledge.\n",
        "\n",
        "Context:\n",
        "{entities}\n",
        "\n",
        "Current conversation:\n",
        "{history}\n",
        "Last line:\n",
        "Human: {input}\n",
        "You:\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "print(entity_memory_conversation_template)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SYhky2EkJa0"
      },
      "source": [
        "## Conversation-Based Entity Memory Example\n",
        "\n",
        "This example demonstrates how to use 'ConversationEntityMemory' to store and manage information about entities mentioned during a conversation. The conversation accumulates ongoing knowledge about these entities while maintaining a natural flow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "QBJ8r5NLkJa0"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(temperature=0)\n",
        "\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    prompt=entity_memory_conversation_template,\n",
        "    memory=ConversationEntityMemory(llm=llm),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzw2XmW1kJa1"
      },
      "source": [
        "## Retrieving Entity Memory\n",
        "\n",
        "Let's examine the conversation history stored in memory using the `load_memory_variables()` method to verify our window-based memory retention."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "igqrJmNEkJa1",
        "outputId": "78ec5fcf-49b8-493d-e4b0-d241e7495734",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=87dc61ad-5397-478a-b979-23511a47da44,id=87dc61ad-5397-478a-b979-23511a47da44; trace=87dc61ad-5397-478a-b979-23511a47da44,id=d732d3d1-130e-4705-92e4-c7f29da789c4\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=1d2defc9-280b-4597-8371-4b42dfc7e08d,id=1d2defc9-280b-4597-8371-4b42dfc7e08d; trace=1d2defc9-280b-4597-8371-4b42dfc7e08d,id=5f6e537d-6bcb-41e9-a90b-8e887f9e3d24; trace=87dc61ad-5397-478a-b979-23511a47da44,id=87dc61ad-5397-478a-b979-23511a47da44; trace=87dc61ad-5397-478a-b979-23511a47da44,id=d732d3d1-130e-4705-92e4-c7f29da789c4\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=653507ff-2849-43e5-91c5-76a19832e66b,id=653507ff-2849-43e5-91c5-76a19832e66b; trace=653507ff-2849-43e5-91c5-76a19832e66b,id=8d9af33e-97e1-4111-955b-de4dd4c280ee; trace=1d2defc9-280b-4597-8371-4b42dfc7e08d,id=5f6e537d-6bcb-41e9-a90b-8e887f9e3d24\n",
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=ed9e9409-49e5-451d-8154-b3defda07ec2,id=ed9e9409-49e5-451d-8154-b3defda07ec2; trace=ed9e9409-49e5-451d-8154-b3defda07ec2,id=cffd5963-fb6e-4a69-ad63-16be01510657; trace=653507ff-2849-43e5-91c5-76a19832e66b,id=653507ff-2849-43e5-91c5-76a19832e66b; trace=653507ff-2849-43e5-91c5-76a19832e66b,id=8d9af33e-97e1-4111-955b-de4dd4c280ee\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "That sounds like a wonderful initiative! Amelia's expertise in landscape photography combined with David's passion for wildlife conservation will surely create a unique and impactful gallery and learning center. By showcasing the beauty of nature through photography, they can raise awareness and support for conservation efforts. It's inspiring to see individuals using their talents to make a positive difference in the world.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langsmith.client:Failed to multipart ingest runs: langsmith.utils.LangSmithAuthError: Authentication failed for https://api.smith.langchain.com/runs/multipart. HTTPError('401 Client Error: Unauthorized for url: https://api.smith.langchain.com/runs/multipart', '{\"detail\":\"Invalid token\"}')trace=1d2defc9-280b-4597-8371-4b42dfc7e08d,id=1d2defc9-280b-4597-8371-4b42dfc7e08d; trace=ed9e9409-49e5-451d-8154-b3defda07ec2,id=ed9e9409-49e5-451d-8154-b3defda07ec2; trace=ed9e9409-49e5-451d-8154-b3defda07ec2,id=cffd5963-fb6e-4a69-ad63-16be01510657\n"
          ]
        }
      ],
      "source": [
        "# Input conversation\n",
        "response = conversation.predict(\n",
        "    input=(\n",
        "        \"Amelia is an award-winning landscape photographer who has traveled around the globe capturing natural wonders. \"\n",
        "        \"David is a wildlife conservationist dedicated to protecting endangered species. \"\n",
        "        \"They are planning to open a nature-inspired photography gallery and learning center that raises funds for conservation projects.\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Print the assistant's response\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the entity memory\n",
        "conversation.memory.entity_store.store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN98J2thEihi",
        "outputId": "76e8779a-a49b-4131-f506-fe220e04c16f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Amelia': 'Amelia is an award-winning landscape photographer who has traveled around the globe capturing natural wonders.',\n",
              " 'David': 'David is a wildlife conservationist dedicated to protecting endangered species.'}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py-test",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
