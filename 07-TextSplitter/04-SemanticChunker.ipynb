{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e00f269d",
   "metadata": {},
   "source": [
    "# SemanticChunker\n",
    "\n",
    "- Author: [Wonyoung Lee](https://github.com/BaBetterB)\n",
    "- Design: []()\n",
    "- Peer Review: []()\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial covers a Text Splitter that splits text based on semantic similarity.\n",
    "The Semantic Chunker is a sophisticated tool within LangChain that brings an intelligent approach to document chunking. Rather than simply dividing text at fixed intervals, it analyzes the semantic meaning of content to create more meaningful divisions. This process relies on OpenAI's embedding model, which evaluates how similar different pieces of text are to each other. The tool offers flexible splitting options, including percentile-based, standard deviation, and interquartile range methods. What sets it apart from traditional text splitters is its ability to maintain context by identifying natural break points in the text, ultimately leading to better performance when working with large language models. By understanding the actual meaning of the content, it creates more coherent and useful chunks that preserve the original document's context and flow.\n",
    "\n",
    " [Greg Kamradt's Notebook](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n",
    "\n",
    "The method divides the text into sentence units, then groups them into three sentences, and merges similar sentences in the embedding space.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environement Setup](#environment-setup)\n",
    "- [Creating a Semantic Chunker](#creating-a-semanticchunker)\n",
    "- [Text Splitting](#text-splitting)\n",
    "- [Breakpoints](#breakpoints)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Greg Kamradt's Notebook](https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb)\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b06978",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b48cce",
   "metadata": {},
   "source": [
    "Load sample text and output the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff3a8858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "!pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e18ec26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain-anthropic\",\n",
    "        \"langchain_community\",\n",
    "        \"langchain_text_splitters\",\n",
    "        \"langchain_openai\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1683c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"SemanticChunker\",  # title\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54038451",
   "metadata": {},
   "source": [
    "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it.\n",
    "\n",
    "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295e7ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration File for Managing API Keys as Environment Variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API Key Information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c170dd43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
      "Example: Vectors of word embeddings can be stored in a database for quick access.\n",
      "Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embed\n"
     ]
    }
   ],
   "source": [
    "# Open the data/appendix-keywords.txt file to create a file object called f.\n",
    "with open(\"./data/appendix-keywords.txt\", encoding=\"utf-8\") as f:\n",
    "\n",
    "    file = f.read()  # Read the contents of the file and save it in the file variable.\n",
    "\n",
    "\n",
    "# Print part of the content read from the file.\n",
    "print(file[:350])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d165846",
   "metadata": {},
   "source": [
    "## Creating a SemanticChunker\n",
    "\n",
    "`SemanticChunker` is one of LangChain's experimental features, which serves to divide text into semantically similar chunks.\n",
    "\n",
    "This allows you to process and analyze text data more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33ae70",
   "metadata": {},
   "source": [
    "Use `SemanticChunker` to divide the text into semantically related chunks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "312e3aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Initialize a semantic chunk splitter using OpenAI embeddings.\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab515b0",
   "metadata": {},
   "source": [
    "## Text Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c9b20b",
   "metadata": {},
   "source": [
    "- Use `text_splitter` to divide the `file` text into document units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dfb5870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_text(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a777bc",
   "metadata": {},
   "source": [
    "Check the divided chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eec69bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks. Example: Vectors of word embeddings can be stored in a database for quick access. Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\n"
     ]
    }
   ],
   "source": [
    "# Print the first chunk among the divided chunks.\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f03b26b",
   "metadata": {},
   "source": [
    "You can convert chunks to documents using the `create_documents()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fadaf823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Search\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks. Example: Vectors of word embeddings can be stored in a database for quick access. Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\n"
     ]
    }
   ],
   "source": [
    "# Split using text_splitter\n",
    "docs = text_splitter.create_documents([file])\n",
    "print(\n",
    "    docs[0].page_content\n",
    ")  # Print the content of the first document among the divided documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1633cf8e",
   "metadata": {},
   "source": [
    "## Breakpoints\n",
    "This chunker works by determining when to \"split\" sentences. \n",
    "This is done by examining the embedding differences between two sentences.\n",
    "If the difference exceeds a certain threshold, the sentences are split.\n",
    "\n",
    "- Reference video: https://youtu.be/8OJC21T2SL4?si=PzUtNGYJ_KULq3-w&t=2580\n",
    "\n",
    "### Percentile\n",
    "The basic splitting method is based on `Percentile`.\n",
    "In this method, all differences between sentences are calculated, then splitting is done based on the specified percentile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "744bbd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # Initialize the semantic chunker using OpenAI's embedding model\n",
    "    OpenAIEmbeddings(),\n",
    "    # Set the split breakpoint type to percentile\n",
    "    breakpoint_threshold_type=\"percentile\",\n",
    "    breakpoint_threshold_amount=70,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aa8318",
   "metadata": {},
   "source": [
    "Check the split results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c7b3262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk 0]\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
      "============================================================\n",
      "[Chunk 1]\n",
      "\n",
      "Example: Vectors of word embeddings can be stored in a database for quick access. Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\n",
      "============================================================\n",
      "[Chunk 2]\n",
      "\n",
      "Example: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17]. Related keywords: natural language processing, vectorization, deep learning\n",
      "\n",
      "Token\n",
      "\n",
      "Definition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases. Example: Split the sentence “I am going to school” into “I am”, “to school”, and “going”. Associated keywords: tokenization, natural language processing, parsing\n",
      "\n",
      "Tokenizer\n",
      "\n",
      "Definition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\n",
      "============================================================\n",
      "[Chunk 3]\n",
      "\n",
      "Example: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”]. Associated keywords: tokenization, natural language processing, parsing\n",
      "\n",
      "VectorStore\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
      "============================================================\n",
      "[Chunk 4]\n",
      "\n",
      "Example: Vectors of word embeddings can be stored in a database for quick access. Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "SQL\n",
      "\n",
      "Definition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.create_documents([file])\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(\n",
    "        doc.page_content\n",
    "    )  # Print the content of the first document among the split documents.\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e83f74",
   "metadata": {},
   "source": [
    "Print the length of `docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20c0cbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))  # Print the length of docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c1c9e8",
   "metadata": {},
   "source": [
    "### Standard Deviation\n",
    "\n",
    "In this method, splitting occurs when there is a difference greater than the specified `breakpoint_threshold_amount` standard deviation.\n",
    "\n",
    "- Set the `breakpoint_threshold_type` parameter to \"standard_deviation\" to specify chunk splitting criteria based on standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16a8d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # Initialize the semantic chunker using OpenAI's embedding model.\n",
    "    OpenAIEmbeddings(),\n",
    "    # Use standard deviation as the splitting criterion.\n",
    "    breakpoint_threshold_type=\"standard_deviation\",\n",
    "    breakpoint_threshold_amount=1.25,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690db96c",
   "metadata": {},
   "source": [
    "Check the split results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1764de39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split using text_splitter.\n",
    "docs = text_splitter.create_documents([file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0743d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk 0]\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks. Example: Vectors of word embeddings can be stored in a database for quick access. Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\n",
      "============================================================\n",
      "[Chunk 1]\n",
      "\n",
      "Example: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17]. Related keywords: natural language processing, vectorization, deep learning\n",
      "\n",
      "Token\n",
      "\n",
      "Definition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases. Example: Split the sentence “I am going to school” into “I am”, “to school”, and “going”. Associated keywords: tokenization, natural language processing, parsing\n",
      "\n",
      "Tokenizer\n",
      "\n",
      "Definition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\n",
      "============================================================\n",
      "[Chunk 2]\n",
      "\n",
      "Example: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”]. Associated keywords: tokenization, natural language processing, parsing\n",
      "\n",
      "VectorStore\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
      "============================================================\n",
      "[Chunk 3]\n",
      "\n",
      "Example: Vectors of word embeddings can be stored in a database for quick access. Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "SQL\n",
      "\n",
      "Definition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\n",
      "============================================================\n",
      "[Chunk 4]\n",
      "\n",
      "Example: SELECT * FROM users WHERE age > 18; looks up information about users who are 18 years old or older. Associated keywords: database, query, data management, data management\n",
      "\n",
      "CSV\n",
      "\n",
      "Definition: CSV(Comma-Separated Values) is a file format for storing data, where each data value is separated by a comma. It is used for simple storage and exchange of tabular data. Example: A CSV file with the headers Name, Age, and Occupation might contain data such as Hong Gil-dong, 30, Developer. Related keywords: data format, file processing, data exchange\n",
      "\n",
      "JSON\n",
      "\n",
      "Definition: JSON(JavaScript Object Notation) is a lightweight data interchange format that represents data objects using text that is readable to both humans and machines. Example: {“Name”: “HongGilDong”, ‘Age’: 30, “Occupation”: “Developer\"} is data in JSON format. Related keywords: data exchange, web development, APIs\n",
      "\n",
      "Transformer\n",
      "\n",
      "Definition: Transformers are a type of deep learning model used in natural language processing, mainly for translation, summarization, text generation, etc. It is based on the Attention mechanism.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "docs = text_splitter.create_documents([file])\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(\n",
    "        doc.page_content\n",
    "    )  # Print the content of the first document among the split documents.\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095170af",
   "metadata": {},
   "source": [
    "Print the length of `docs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee9f46ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))  # Print the length of docs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b03d9b",
   "metadata": {},
   "source": [
    "### Interquartile\n",
    "\n",
    "This method uses interquartile range to split chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb408177",
   "metadata": {},
   "source": [
    "- Set the `breakpoint_threshold_type` parameter to \"interquartile\" to specify chunk splitting criteria based on interquartile range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f32f5fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = SemanticChunker(\n",
    "    # Initialize the semantic chunk splitter using OpenAI's embedding model.\n",
    "    OpenAIEmbeddings(),\n",
    "    # Set the breakpoint threshold type to interquartile range.\n",
    "    breakpoint_threshold_type=\"interquartile\",\n",
    "    breakpoint_threshold_amount=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e0d2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Chunk 0]\n",
      "\n",
      "Semantic Search\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
      "============================================================\n",
      "[Chunk 1]\n",
      "\n",
      "Example: Vectors of word embeddings can be stored in a database for quick access. Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "Embedding\n",
      "\n",
      "Definition: Embedding is the process of converting textual data, such as words or sentences, into a low-dimensional, continuous vector. This allows computers to understand and process the text.\n",
      "============================================================\n",
      "[Chunk 2]\n",
      "\n",
      "Example: Represent the word “apple” as a vector such as [0.65, -0.23, 0.17]. Related keywords: natural language processing, vectorization, deep learning\n",
      "\n",
      "Token\n",
      "\n",
      "Definition: A token is a breakup of text into smaller units. These can typically be words, sentences, or phrases. Example: Split the sentence “I am going to school” into “I am”, “to school”, and “going”. Associated keywords: tokenization, natural language processing, parsing\n",
      "\n",
      "Tokenizer\n",
      "\n",
      "Definition: A tokenizer is a tool that splits text data into tokens. It is used to preprocess data in natural language processing.\n",
      "============================================================\n",
      "[Chunk 3]\n",
      "\n",
      "Example: Split the sentence “I love programming.” into [“I”, “love”, “programming”, “.”]. Associated keywords: tokenization, natural language processing, parsing\n",
      "\n",
      "VectorStore\n",
      "\n",
      "Definition: A vector store is a system that stores data converted to vector format. It is used for search, classification, and other data analysis tasks.\n",
      "============================================================\n",
      "[Chunk 4]\n",
      "\n",
      "Example: Vectors of word embeddings can be stored in a database for quick access. Related keywords: embedding, database, vectorization, vectorization\n",
      "\n",
      "SQL\n",
      "\n",
      "Definition: SQL(Structured Query Language) is a programming language for managing data in a database. You can query, modify, insert, delete, and more data.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Split using text_splitter.\n",
    "docs = text_splitter.create_documents([file])\n",
    "\n",
    "# Print the results.\n",
    "for i, doc in enumerate(docs[:5]):\n",
    "    print(f\"[Chunk {i}]\", end=\"\\n\\n\")\n",
    "    print(\n",
    "        doc.page_content\n",
    "    )  # Print the content of the first document among the split documents.\n",
    "    print(\"===\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d186bb7",
   "metadata": {},
   "source": [
    "Print the length of `docs`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c693c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))  # Print the length of docs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-HDS-w_h3-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
