{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LlamaCpp Embeddings With Langchain\n",
        "\n",
        "- Author: [Yongdam Kim](https://github.com/dancing-with-coffee/)\n",
        "- Peer Review: [Teddy](https://github.com/teddylee777)\n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This tutorial covers how to perform **Text Embedding** using **Llama-cpp** and **Langchain**.\n",
        "\n",
        "**Llama-cpp** is an open-source package implemented in C++ that allows you to use LLMs such as llama very efficiently locally.\n",
        "\n",
        "In this tutorial, we will create a simple example to measure similarity between `Documents` and an input `Query` using **Llama-cpp** and **Langchain**.\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)\n",
        "- [Environment Setup](#environment-setup)\n",
        "- [Llama-cpp Installation and Model Serving](#llama-cpp-installation-and-model-serving)\n",
        "- [Identify Supported Embedding Models and Serving Model](#identify-supported-embedding-models-and-serving-model)\n",
        "- [Model Load and Embedding](#model-load-and-embedding)\n",
        "- [The similarity calculation results](#the-similarity-calculation-results)\n",
        "\n",
        "### References\n",
        "\n",
        "- [Cosine Similarity](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
        "- [Llama-cpp Python GitHub](https://github.com/abetlen/llama-cpp-python)\n",
        "- [LangChain Documentation](https://langchain.readthedocs.io/en/latest/)\n",
        "- [Cosine Similarity - Wikipedia](https://en.wikipedia.org/wiki/Cosine_similarity)\n",
        "- [CompendiumLabs/bge-large-en-v1.5-gguf - Hugging Face](https://huggingface.co/CompendiumLabs/bge-large-en-v1.5-gguf/tree/main)\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
        "- You can check out the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution_count": 1
      },
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution_count": 2
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langchain_community\",\n",
        "        \"llama-cpp-python\",\n",
        "        \"scikit-learn\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"LlamaCpp-Embeddings-With-Langchain\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can alternatively set `LANGCHAIN_API_KEY` in `.env` file and load it. \n",
        "\n",
        "[Note] This is not necessary if you've already set `LANGCHAIN_API_KEY` in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Llama-cpp Installation and Model Serving\n",
        "\n",
        "Llama-cpp is an open-source project that makes it easy to run large language models (LLMs) locally. It allows you to download and run various LLMs on your own computer, giving you the freedom to experiment with AI models.\n",
        "\n",
        "To install **llama-cpp-python**:\n",
        "```bash\n",
        "pip install llama-cpp-python\n",
        "```\n",
        "\n",
        "1. Make sure you have the required environment for C++ compilation (e.g., on Linux or macOS). \n",
        "2. Download or specify your chosen embedding model file (e.g., `CompendiumLabs/bge-large-en-v1.5-gguf`).\n",
        "3. Here, we use `bge-large-en-v1.5-q8_0.gguf` as an example and you can download it from [CompendiumLabs/bge-large-en-v1.5-gguf - Hugging Face](https://huggingface.co/CompendiumLabs/bge-large-en-v1.5-gguf/tree/main).\n",
        "4. Check that `llama-cpp-python` can find the model path.\n",
        "\n",
        "Below, we will demonstrate how to serve a LLaMA model using Llama-cpp. You can follow the official [llama-cpp-python documentation](https://github.com/abetlen/llama-cpp-python) for more details."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Identify Supported Embedding Models and Serving Model\n",
        "\n",
        "You can find a variety of embedding models, which typically come in different quantizations (e.g., q4_0, q4_1, q5_0, q8_0, etc.).\n",
        "\n",
        "**1. Search models**\n",
        "- You can look for models on Hugging Face or other community websites.\n",
        "\n",
        "**2. Download or Pull a Model**\n",
        "- For instance, you could download from Hugging Face if the model is hosted.\n",
        "\n",
        "**3. Verify the Model**\n",
        "- Check that the `.bin` (or `.gguf`) file is accessible to your environment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Load and Embedding\n",
        "\n",
        "Now that you have installed `llama-cpp-python` and have downloaded a model, let's see how to load it and use it for text embedding.\n",
        "\n",
        "Below, we define a `Query` or some `Documents` to embed using `Llama-cpp` within LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution_count": 3
      },
      "outputs": [],
      "source": [
        "from langchain_community.embeddings import LlamaCppEmbeddings\n",
        "\n",
        "# Example query and documents\n",
        "query = \"What is LangChain?\"\n",
        "docs = [\n",
        "    \"LangChain is an open-source framework designed to facilitate the development of applications powered by large language models (LLMs). It provides tools and components to build end-to-end workflows for tasks like document retrieval, chatbots, summarization, data analysis, and more.\",\n",
        "    \"Spaghetti Carbonara is a traditional Italian pasta dish made with eggs, cheese, pancetta, and pepper. It's simple yet incredibly delicious. Typically served with spaghetti, but can also be enjoyed with other pasta types.\",\n",
        "    \"The tropical island of Bali offers stunning beaches, volcanic mountains, lush forests, and vibrant coral reefs. Travelers often visit for surfing, yoga retreats, and the unique Balinese Hindu culture.\",\n",
        "    \"C++ is a high-performance programming language widely used in system/software development, game programming, and real-time simulations. It supports both procedural and object-oriented paradigms.\",\n",
        "    \"In astronomy, the Drake Equation is a probabilistic argument used to estimate the number of active, communicative extraterrestrial civilizations in the Milky Way galaxy. It takes into account factors such as star formation rate and fraction of habitable planets.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load the Embedding Model\n",
        "\n",
        "Below is how you can initialize the `LlamaCppEmbeddings` class by specifying the path to your LLaMA model file (`model_path`).\n",
        "\n",
        "For example, you might have a downloaded model path: `./bge-large-en-v1.5-q8_0.gguf`.\n",
        "\n",
        "We demonstrate how to instantiate the embeddings class and then embed queries and documents using Llama-cpp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution_count": 7
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_load_model_from_file: using device Metal (Apple M3 Max) - 49151 MiB free\n",
            "llama_model_loader: loaded meta data with 24 key-value pairs and 389 tensors from bge-large-en-v1.5-q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = bert\n",
            "llama_model_loader: - kv   1:                               general.name str              = bge-large-en-v1.5\n",
            "llama_model_loader: - kv   2:                           bert.block_count u32              = 24\n",
            "llama_model_loader: - kv   3:                        bert.context_length u32              = 512\n",
            "llama_model_loader: - kv   4:                      bert.embedding_length u32              = 1024\n",
            "llama_model_loader: - kv   5:                   bert.feed_forward_length u32              = 4096\n",
            "llama_model_loader: - kv   6:                  bert.attention.head_count u32              = 16\n",
            "llama_model_loader: - kv   7:          bert.attention.layer_norm_epsilon f32              = 0.000000\n",
            "llama_model_loader: - kv   8:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv   9:                      bert.attention.causal bool             = false\n",
            "llama_model_loader: - kv  10:                          bert.pooling_type u32              = 2\n",
            "llama_model_loader: - kv  11:            tokenizer.ggml.token_type_count u32              = 2\n",
            "llama_model_loader: - kv  12:                tokenizer.ggml.bos_token_id u32              = 101\n",
            "llama_model_loader: - kv  13:                tokenizer.ggml.eos_token_id u32              = 102\n",
            "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = bert\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,30522]   = [\"[PAD]\", \"[unused0]\", \"[unused1]\", \"...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,30522]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,30522]   = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 100\n",
            "llama_model_loader: - kv  19:          tokenizer.ggml.seperator_token_id u32              = 102\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  21:                tokenizer.ggml.cls_token_id u32              = 101\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.mask_token_id u32              = 103\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  244 tensors\n",
            "llama_model_loader: - type q8_0:  145 tensors\n",
            "llm_load_vocab: control token:    100 '[UNK]' is not marked as EOG\n",
            "llm_load_vocab: control token:    101 '[CLS]' is not marked as EOG\n",
            "llm_load_vocab: control token:      0 '[PAD]' is not marked as EOG\n",
            "llm_load_vocab: control token:    102 '[SEP]' is not marked as EOG\n",
            "llm_load_vocab: control token:    103 '[MASK]' is not marked as EOG\n",
            "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "llm_load_vocab: special tokens cache size = 5\n",
            "llm_load_vocab: token to piece cache size = 0.2032 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = bert\n",
            "llm_load_print_meta: vocab type       = WPM\n",
            "llm_load_print_meta: n_vocab          = 30522\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 512\n",
            "llm_load_print_meta: n_embd           = 1024\n",
            "llm_load_print_meta: n_layer          = 24\n",
            "llm_load_print_meta: n_head           = 16\n",
            "llm_load_print_meta: n_head_kv        = 16\n",
            "llm_load_print_meta: n_rot            = 64\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 64\n",
            "llm_load_print_meta: n_embd_head_v    = 64\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 1.0e-12\n",
            "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 4096\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 0\n",
            "llm_load_print_meta: pooling type     = 2\n",
            "llm_load_print_meta: rope type        = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 512\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 335M\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 334.09 M\n",
            "llm_load_print_meta: model size       = 340.90 MiB (8.56 BPW) \n",
            "llm_load_print_meta: general.name     = bge-large-en-v1.5\n",
            "llm_load_print_meta: BOS token        = 101 '[CLS]'\n",
            "llm_load_print_meta: EOS token        = 102 '[SEP]'\n",
            "llm_load_print_meta: UNK token        = 100 '[UNK]'\n",
            "llm_load_print_meta: SEP token        = 102 '[SEP]'\n",
            "llm_load_print_meta: PAD token        = 0 '[PAD]'\n",
            "llm_load_print_meta: CLS token        = 101 '[CLS]'\n",
            "llm_load_print_meta: MASK token       = 103 '[MASK]'\n",
            "llm_load_print_meta: LF token         = 0 '[PAD]'\n",
            "llm_load_print_meta: EOG token        = 102 '[SEP]'\n",
            "llm_load_print_meta: max token length = 21\n",
            "llm_load_tensors: tensor 'token_embd.weight' (q8_0) (and 4 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "ggml_backend_metal_log_allocated_size: allocated buffer, size =   307.23 MiB, (  307.31 / 49152.00)\n",
            "llm_load_tensors: offloading 24 repeating layers to GPU\n",
            "llm_load_tensors: offloading output layer to GPU\n",
            "llm_load_tensors: offloaded 25/25 layers to GPU\n",
            "llm_load_tensors: Metal_Mapped model buffer size =   307.23 MiB\n",
            "llm_load_tensors:   CPU_Mapped model buffer size =    33.69 MiB\n",
            "................................................................................\n",
            "llama_new_context_with_model: n_seq_max     = 1\n",
            "llama_new_context_with_model: n_ctx         = 512\n",
            "llama_new_context_with_model: n_ctx_per_seq = 512\n",
            "llama_new_context_with_model: n_batch       = 512\n",
            "llama_new_context_with_model: n_ubatch      = 512\n",
            "llama_new_context_with_model: flash_attn    = 0\n",
            "llama_new_context_with_model: freq_base     = 10000.0\n",
            "llama_new_context_with_model: freq_scale    = 1\n",
            "ggml_metal_init: allocating\n",
            "ggml_metal_init: found device: Apple M3 Max\n",
            "ggml_metal_init: picking default device: Apple M3 Max\n",
            "ggml_metal_init: using embedded metal library\n",
            "ggml_metal_init: GPU name:   Apple M3 Max\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
            "ggml_metal_init: simdgroup reduction   = true\n",
            "ggml_metal_init: simdgroup matrix mul. = true\n",
            "ggml_metal_init: has bfloat            = true\n",
            "ggml_metal_init: use bfloat            = false\n",
            "ggml_metal_init: hasUnifiedMemory      = true\n",
            "ggml_metal_init: recommendedMaxWorkingSetSize  = 51539.61 MB\n",
            "ggml_metal_init: loaded kernel_add                                    0x114ec12e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_add_row                                0x114ec5cc0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sub                                    0x122f419f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sub_row                                0x1132e56b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul                                    0x11350a220 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_row                                0x114ec7340 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_div                                    0x122f42030 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_div_row                                0x122f41490 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_repeat_f32                             0x1120731c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_repeat_f16                             0x112072100 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_repeat_i32                             0x112072cf0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_repeat_i16                             0x112074df0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_scale                                  0x112075900 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_scale_4                                0x114ec8850 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_clamp                                  0x122f42a10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_tanh                                   0x122f43a50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_relu                                   0x124820450 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sigmoid                                0x1132e2510 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_gelu                                   0x112075ed0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_gelu_4                                 0x122f44430 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_gelu_quick                             0x124820710 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_gelu_quick_4                           0x114ec7f20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_silu                                   0x114ec9b50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_silu_4                                 0x122f44eb0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_elu                                    0x112075460 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_soft_max_f16                           0x1132dd3f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x1132e0bd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_soft_max_f32                           0x1132e6430 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x112076be0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_diag_mask_inf                          0x1248229b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x124823260 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_f32                           0x1120762a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_f16                           0x124821ad0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
            "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x1248247f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x124824cd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x1132e66f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x1132e69b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x1132e6c70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x1132e6f30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x112077aa0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x124825590 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x1122461c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x114eca0e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x114ecb380 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x1132e71f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x1120789e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x1120793e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x11207a780 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x11207acf0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x11207b910 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x114ecaea0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x114ecc9e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_i32                           0x1248250b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rms_norm                               0x124825970 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_group_norm                             0x1132e74b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_norm                                   0x1132e7770 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x11207c220 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x114eccf50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x114ecdc10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
            "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x112246a60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x114ecdfa0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x11207ca40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x112247280 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x1132e7a30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x122f454f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x1132e7cf0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x1132e7fb0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x114ece860 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x114ecf100 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x124826e50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x114ececb0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x112247b00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x1122483d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x1132e8270 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x1132e8530 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x1132e8e50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x1132e9710 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x1132e9fa0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x122f45e00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x1132ea870 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x1132eb140 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x11207ce70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x122f46720 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x114ecfa20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x112248cf0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x114ed0bc0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x1132eba30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x11207d790 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x114ed14c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x114ed01d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x122f47010 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x1132ec340 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x114ed26c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x1122495c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x117205ac0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x114805490 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x122f478e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x124827750 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x112249d50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x114ed2fc0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x1172051c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x11207e4b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x1132ec860 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x1132ed120 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x1132eda20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x1132ee310 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x122f484f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x1132eec00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x1132ef4d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x114ed38c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x114ed4100 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x114ed4990 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x114ed51d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x11224a250 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x114ed5a30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x124828050 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x124828910 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x122f49110 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x113509920 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x1248291d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x1132efd20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x114ed1cd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x1132f0650 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x122f4a130 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x1132f0f30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x1132f1830 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x114ed6c30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x114ed7540 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x11207edd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x114ed7e10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x11207f6d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x124829ac0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x11224adb0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x12482a3e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x1132f2130 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x12482aca0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x11224b6d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x12482b600 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x1132f2a90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x1132f3360 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x11224bff0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x114ed8730 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x114ed9040 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x114ed9870 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x114eda0b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
            "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x1132f3c10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x114eda8f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x1132f4470 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x114edb130 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x114edb930 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x1132f4c90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x122f4a9e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x114edc170 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x114edc9b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x122f4b270 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x12482bf30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x11224c8e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x12482c870 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x122f4ba90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x1132f54c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x114edd1f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x1132f5db0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x114eddab0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x114ede3a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x12482d190 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x11207ffe0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x1120808c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x114edecb0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x1132f66c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x122f4c3d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x114edf580 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x122f4cd10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x122f4d650 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x1120811a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x1132f6fa0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x122f4df70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x114edfe80 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x114ee0780 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x122f4e850 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x122f4f150 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x122f4fa50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x1132f7880 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x12482da60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x1132f8180 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x11224d1c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rope_norm_f32                          0x1132f8a20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rope_norm_f16                          0x12482e730 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rope_neox_f32                          0x112081740 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rope_neox_f16                          0x122f506f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_im2col_f16                             0x122f50bb0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_im2col_f32                             0x11224da60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x1132f8e60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x1132f9230 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x122f514e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x114ee1a30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_upscale_f32                            0x114ee1ff0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_pad_f32                                0x114ee27b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x122f51f50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x122f52d60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_arange_f32                             0x122f53650 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x122f53ed0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x1132faab0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x114ee36c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x112081ba0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x1120824b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x122f54380 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x114ee2f50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x114ee42a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x112083230 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x114ee50a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x1132fa3b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x122f54c30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x112083690 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x122f55590 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x122f559c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x1132fb7b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x112082c70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x114ee5500 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x1132fc0b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x114ee5e00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x1120844d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x1132fc9b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x1132fd290 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x1132fbc50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x114ee6bd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x114ee7030 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x1132fdac0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x1132fe3d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x1132ff6f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x122f562a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x114ee7970 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x114ee6680 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x12482f050 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x114ee8ae0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x11224e300 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x122f57480 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x114ee81c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x114ee9350 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x117206640 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x11224ed40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x114eea5d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x11224fb40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x114eeaf40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x122f57950 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x122f56680 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x114eeb7e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x114ee9c40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x1120859c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x122f58a80 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x114eebfe0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x114eed290 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_set_f32                                0x122f580d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_set_i32                                0x114eec8d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x114eedf30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x112085570 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
            "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x114eee7b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x11224ff40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x122f59730 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x112085de0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x114eef000 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x12482ea70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x122f59fb0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x12482f470 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_concat                                 0x114eefc90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sqr                                    0x1132ffb50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sqrt                                   0x114ef00e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sin                                    0x114ef0b00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cos                                    0x114ef1690 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sum_rows                               0x112086650 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_argmax                                 0x124b045f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x122f5a410 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x114ef2060 | th_max = 1024 | th_width =   32\n",
            "llama_kv_cache_init:      Metal KV buffer size =    48.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   48.00 MiB, K (f16):   24.00 MiB, V (f16):   24.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB\n",
            "llama_new_context_with_model:      Metal compute buffer size =    25.00 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     5.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 849\n",
            "llama_new_context_with_model: graph splits = 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding model has been successfully loaded.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.cls_token_id': '101', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.seperator_token_id': '102', 'tokenizer.ggml.unknown_token_id': '100', 'general.quantization_version': '2', 'tokenizer.ggml.token_type_count': '2', 'general.file_type': '7', 'tokenizer.ggml.eos_token_id': '102', 'bert.context_length': '512', 'bert.pooling_type': '2', 'tokenizer.ggml.bos_token_id': '101', 'bert.attention.head_count': '16', 'bert.feed_forward_length': '4096', 'tokenizer.ggml.mask_token_id': '103', 'tokenizer.ggml.model': 'bert', 'bert.attention.causal': 'false', 'general.name': 'bge-large-en-v1.5', 'bert.block_count': '24', 'bert.attention.layer_norm_epsilon': '0.000000', 'bert.embedding_length': '1024', 'general.architecture': 'bert'}\n",
            "Using fallback chat format: llama-2\n"
          ]
        }
      ],
      "source": [
        "# Load the Llama-cpp Embedding Model\n",
        "model_path = \"bge-large-en-v1.5-q8_0.gguf\"  # example path\n",
        "\n",
        "embedder = LlamaCppEmbeddings(model_path=model_path, n_gpu_layers=-1)\n",
        "print(\"Embedding model has been successfully loaded.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Embedding Queries and Documents\n",
        "\n",
        "Now let's embed both the `query` and the `documents`. We will verify the dimension of the output vectors.\n",
        "\n",
        "However, there is currently one issue that cannot be resolved when using the latest model with `LlamaCppEmbeddings`. I will post the link to the issue below, so please check it out and if it is resolved in the latest version, you can use it as instructed in the original langchain official tutorial.\n",
        "\n",
        "- Issue link : https://github.com/langchain-ai/langchain/issues/22532"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution_count": 8
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "llama_load_model_from_file: using device Metal (Apple M3 Max) - 48765 MiB free\n",
            "llama_model_loader: loaded meta data with 24 key-value pairs and 389 tensors from bge-large-en-v1.5-q8_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = bert\n",
            "llama_model_loader: - kv   1:                               general.name str              = bge-large-en-v1.5\n",
            "llama_model_loader: - kv   2:                           bert.block_count u32              = 24\n",
            "llama_model_loader: - kv   3:                        bert.context_length u32              = 512\n",
            "llama_model_loader: - kv   4:                      bert.embedding_length u32              = 1024\n",
            "llama_model_loader: - kv   5:                   bert.feed_forward_length u32              = 4096\n",
            "llama_model_loader: - kv   6:                  bert.attention.head_count u32              = 16\n",
            "llama_model_loader: - kv   7:          bert.attention.layer_norm_epsilon f32              = 0.000000\n",
            "llama_model_loader: - kv   8:                          general.file_type u32              = 7\n",
            "llama_model_loader: - kv   9:                      bert.attention.causal bool             = false\n",
            "llama_model_loader: - kv  10:                          bert.pooling_type u32              = 2\n",
            "llama_model_loader: - kv  11:            tokenizer.ggml.token_type_count u32              = 2\n",
            "llama_model_loader: - kv  12:                tokenizer.ggml.bos_token_id u32              = 101\n",
            "llama_model_loader: - kv  13:                tokenizer.ggml.eos_token_id u32              = 102\n",
            "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = bert\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,30522]   = [\"[PAD]\", \"[unused0]\", \"[unused1]\", \"...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,30522]   = [-1000.000000, -1000.000000, -1000.00...\n",
            "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,30522]   = [3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 100\n",
            "llama_model_loader: - kv  19:          tokenizer.ggml.seperator_token_id u32              = 102\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  21:                tokenizer.ggml.cls_token_id u32              = 101\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.mask_token_id u32              = 103\n",
            "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:  244 tensors\n",
            "llama_model_loader: - type q8_0:  145 tensors\n",
            "llm_load_vocab: control token:    100 '[UNK]' is not marked as EOG\n",
            "llm_load_vocab: control token:    101 '[CLS]' is not marked as EOG\n",
            "llm_load_vocab: control token:      0 '[PAD]' is not marked as EOG\n",
            "llm_load_vocab: control token:    102 '[SEP]' is not marked as EOG\n",
            "llm_load_vocab: control token:    103 '[MASK]' is not marked as EOG\n",
            "llm_load_vocab: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
            "llm_load_vocab: special tokens cache size = 5\n",
            "llm_load_vocab: token to piece cache size = 0.2032 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = bert\n",
            "llm_load_print_meta: vocab type       = WPM\n",
            "llm_load_print_meta: n_vocab          = 30522\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: vocab_only       = 0\n",
            "llm_load_print_meta: n_ctx_train      = 512\n",
            "llm_load_print_meta: n_embd           = 1024\n",
            "llm_load_print_meta: n_layer          = 24\n",
            "llm_load_print_meta: n_head           = 16\n",
            "llm_load_print_meta: n_head_kv        = 16\n",
            "llm_load_print_meta: n_rot            = 64\n",
            "llm_load_print_meta: n_swa            = 0\n",
            "llm_load_print_meta: n_embd_head_k    = 64\n",
            "llm_load_print_meta: n_embd_head_v    = 64\n",
            "llm_load_print_meta: n_gqa            = 1\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 1.0e-12\n",
            "llm_load_print_meta: f_norm_rms_eps   = 0.0e+00\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 4096\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 0\n",
            "llm_load_print_meta: pooling type     = 2\n",
            "llm_load_print_meta: rope type        = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 10000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_ctx_orig_yarn  = 512\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: ssm_dt_b_c_rms   = 0\n",
            "llm_load_print_meta: model type       = 335M\n",
            "llm_load_print_meta: model ftype      = Q8_0\n",
            "llm_load_print_meta: model params     = 334.09 M\n",
            "llm_load_print_meta: model size       = 340.90 MiB (8.56 BPW) \n",
            "llm_load_print_meta: general.name     = bge-large-en-v1.5\n",
            "llm_load_print_meta: BOS token        = 101 '[CLS]'\n",
            "llm_load_print_meta: EOS token        = 102 '[SEP]'\n",
            "llm_load_print_meta: UNK token        = 100 '[UNK]'\n",
            "llm_load_print_meta: SEP token        = 102 '[SEP]'\n",
            "llm_load_print_meta: PAD token        = 0 '[PAD]'\n",
            "llm_load_print_meta: CLS token        = 101 '[CLS]'\n",
            "llm_load_print_meta: MASK token       = 103 '[MASK]'\n",
            "llm_load_print_meta: LF token         = 0 '[PAD]'\n",
            "llm_load_print_meta: EOG token        = 102 '[SEP]'\n",
            "llm_load_print_meta: max token length = 21\n",
            "llm_load_tensors: tensor 'token_embd.weight' (q8_0) (and 4 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
            "ggml_backend_metal_log_allocated_size: allocated buffer, size =   307.23 MiB, (  693.44 / 49152.00)\n",
            "llm_load_tensors: offloading 24 repeating layers to GPU\n",
            "llm_load_tensors: offloading output layer to GPU\n",
            "llm_load_tensors: offloaded 25/25 layers to GPU\n",
            "llm_load_tensors: Metal_Mapped model buffer size =   307.23 MiB\n",
            "llm_load_tensors:   CPU_Mapped model buffer size =    33.69 MiB\n",
            "................................................................................\n",
            "llama_new_context_with_model: n_seq_max     = 1\n",
            "llama_new_context_with_model: n_ctx         = 512\n",
            "llama_new_context_with_model: n_ctx_per_seq = 512\n",
            "llama_new_context_with_model: n_batch       = 512\n",
            "llama_new_context_with_model: n_ubatch      = 512\n",
            "llama_new_context_with_model: flash_attn    = 0\n",
            "llama_new_context_with_model: freq_base     = 10000.0\n",
            "llama_new_context_with_model: freq_scale    = 1\n",
            "ggml_metal_init: allocating\n",
            "ggml_metal_init: found device: Apple M3 Max\n",
            "ggml_metal_init: picking default device: Apple M3 Max\n",
            "ggml_metal_init: using embedded metal library\n",
            "ggml_metal_init: GPU name:   Apple M3 Max\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
            "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
            "ggml_metal_init: simdgroup reduction   = true\n",
            "ggml_metal_init: simdgroup matrix mul. = true\n",
            "ggml_metal_init: has bfloat            = true\n",
            "ggml_metal_init: use bfloat            = false\n",
            "ggml_metal_init: hasUnifiedMemory      = true\n",
            "ggml_metal_init: recommendedMaxWorkingSetSize  = 51539.61 MB\n",
            "ggml_metal_init: loaded kernel_add                                    0x114ef1be0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_add_row                                0x114ef3670 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sub                                    0x114ee8f70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sub_row                                0x114ef4700 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul                                    0x122f550c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_row                                0x1132fe040 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_div                                    0x1132f94f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_div_row                                0x124b04170 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_repeat_f32                             0x114ef4f50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_repeat_f16                             0x124b04ed0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_repeat_i32                             0x124b05190 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_repeat_i16                             0x122f5a800 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_scale                                  0x114ef4ad0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_scale_4                                0x124b05540 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_clamp                                  0x114ef5b00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_tanh                                   0x114ef6140 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_relu                                   0x114ef6560 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sigmoid                                0x112086a50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_gelu                                   0x124b05800 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_gelu_4                                 0x124b05fd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_gelu_quick                             0x114ef7530 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_gelu_quick_4                           0x124b06510 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_silu                                   0x114ef8010 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_silu_4                                 0x124b06a50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_elu                                    0x124b06f90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_soft_max_f16                           0x124b074d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x112084d20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_soft_max_f32                           0x122f56b60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x11204a450 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_diag_mask_inf                          0x122f59b30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x124b07790 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_f32                           0x112083b60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_f16                           0x124b07a50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
            "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x124b07d10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x112087ab0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x112087d70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x122f5ac80 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x114ef8570 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x12482f840 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x122f5b1d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x124b07fd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x112088030 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x1120882f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x122f5b7a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x122f5bcd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x124b08290 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x114ef97b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x114ef8d70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x124b08550 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x1120885b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x124b08810 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x122f5bf90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_get_rows_i32                           0x122f5c250 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rms_norm                               0x112088870 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_group_norm                             0x122f5c510 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_norm                                   0x112088e90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x122f5c7d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x124b08ad0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x112089680 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
            "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
            "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x122f5ca90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x114efaff0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x114efb5c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x122f5cd50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x114efba20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x114efc230 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x124b08d90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x112089f40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x122f5d010 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x112250310 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x124b09050 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x12481fe30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x122f5d2d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x122f5d590 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x122f5d850 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x1122505d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x114efca40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x114efd340 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x124b09700 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x114efdc40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x114efe560 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x114eff460 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x12482fbe0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x124b09ff0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x11208a730 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x127d04160 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x124b0a8c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x127d04780 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x124b0b1a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x122f5e0e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x122f5e9c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x122f5f2f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x122f5fbd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x127d05090 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x127d05960 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x122f604e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x122f60da0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x127d06250 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x124830080 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x11208b060 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x124830340 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x11208b920 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x11208c200 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x127d06b20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x127d07410 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x124b0ba50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x11208cb00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x124b0c320 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x112250890 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x124b0c8c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x127d079b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x124b0ccf0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x112250b50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x124830700 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x124b0d4d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x11208d3f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x127d07e00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x11208db70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x124b0dda0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x112250e10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x124830a90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x124b0e680 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x1248312d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x124b0ef90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x124b0f840 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x127d08690 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x11208e050 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x124831c20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x11208e9b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x11208f250 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x1122510d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x127d08f70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x124b10120 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x124b10a40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x122f61c10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x127d09880 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x127d0a140 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x122f624b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x11208fb60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x124b112f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x127d0aa90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x122f62d80 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x112090460 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x122f63700 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x127d0b340 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x124b11ba0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
            "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x122f643d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x112090d50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x127d0bb50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x124b123d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x122f64830 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x127d0c370 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x112091580 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x124b12c20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x124b13480 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x122f65530 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x124b13ce0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x124b145b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x127d0cb70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x124832500 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x127d0d460 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x127d0e070 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x122f65040 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x122f66210 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x124b14ed0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x124b15800 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x122f66af0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x1122516f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x124832ee0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x112251fd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x112091d80 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x112092680 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x112092f50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x122f673f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x1122528d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x127d0e940 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x127d0f220 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x124b16100 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x1248337b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x124b169e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x127d0fae0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x112093830 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x112094130 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x124b17320 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x124b17c20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x122f67ce0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rope_norm_f32                          0x124b184d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rope_norm_f16                          0x127d10400 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rope_neox_f32                          0x127d107f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_rope_neox_f16                          0x127d11030 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_im2col_f16                             0x112094a30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_im2col_f32                             0x122f68600 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x122f68ed0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x112095260 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x127d118d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x127d13090 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_upscale_f32                            0x122f69de0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_pad_f32                                0x127d13350 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x127d13810 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x112095c40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_arange_f32                             0x127d147d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x127d14160 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x124b18d40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x122f6a5c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x127d14a90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x112096600 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x122f6b310 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x122f6bbd0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x124b19250 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x122f6ae70 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x124b1a460 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x1120973c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x112252f90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x124b195d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x122f6cda0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x122f6d2b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x122f6dbc0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x112097820 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x124b1b1d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x122f6e460 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x112098130 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x112098a40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x1122538c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x112099320 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x127d16290 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x127d166f0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x127d16ff0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x122f6f1a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x124b19ea0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x124b1b6b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x122f6f690 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x127d178e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x127d18230 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x122f6f9d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x127d18b30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x124b1ba00 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x124b1cc50 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x122f711a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x122f71ab0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x1248340c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x122f71f20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x122f72cc0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x122f735e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x124b1d570 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x122f73050 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x127d18f40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x112099b30 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x11209a980 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x11209a380 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x124b1c350 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x127d19cf0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x124b1e6d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_set_f32                                0x124b1df80 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_set_i32                                0x124834d10 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x124b1f400 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x127d1a9b0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
            "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x124b20030 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x11209b6a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
            "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x122f74220 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x1248351d0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x124b208a0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x122f75100 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x122f75730 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x127d1a4e0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_concat                                 0x11209be60 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sqr                                    0x122f76290 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sqrt                                   0x127d1b4c0 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sin                                    0x122f76d20 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_cos                                    0x122f77750 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_sum_rows                               0x124b20480 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_argmax                                 0x124b21d40 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x127d1bd90 | th_max = 1024 | th_width =   32\n",
            "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x124b222c0 | th_max = 1024 | th_width =   32\n",
            "llama_kv_cache_init:      Metal KV buffer size =    48.00 MiB\n",
            "llama_new_context_with_model: KV self size  =   48.00 MiB, K (f16):   24.00 MiB, V (f16):   24.00 MiB\n",
            "llama_new_context_with_model:        CPU  output buffer size =     0.00 MiB\n",
            "llama_new_context_with_model:      Metal compute buffer size =    25.00 MiB\n",
            "llama_new_context_with_model:        CPU compute buffer size =     5.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 849\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
            "Model metadata: {'tokenizer.ggml.cls_token_id': '101', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.seperator_token_id': '102', 'tokenizer.ggml.unknown_token_id': '100', 'general.quantization_version': '2', 'tokenizer.ggml.token_type_count': '2', 'general.file_type': '7', 'tokenizer.ggml.eos_token_id': '102', 'bert.context_length': '512', 'bert.pooling_type': '2', 'tokenizer.ggml.bos_token_id': '101', 'bert.attention.head_count': '16', 'bert.feed_forward_length': '4096', 'tokenizer.ggml.mask_token_id': '103', 'tokenizer.ggml.model': 'bert', 'bert.attention.causal': 'false', 'general.name': 'bge-large-en-v1.5', 'bert.block_count': '24', 'bert.attention.layer_norm_epsilon': '0.000000', 'bert.embedding_length': '1024', 'general.architecture': 'bert'}\n",
            "Using fallback chat format: llama-2\n",
            "llama_perf_context_print:        load time =      31.06 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /     8 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =      31.09 ms /     9 tokens\n",
            "llama_perf_context_print:        load time =      31.06 ms\n",
            "llama_perf_context_print: prompt eval time =       0.00 ms /   243 tokens (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:        eval time =       0.00 ms /     1 runs   (    0.00 ms per token,      inf tokens per second)\n",
            "llama_perf_context_print:       total time =      47.36 ms /   244 tokens\n"
          ]
        }
      ],
      "source": [
        "# from langchain tutorial\n",
        "\n",
        "\"\"\"\n",
        "embedded_query = llama_embeddings.embed_query(query)\n",
        "embedded_docs = llama_embeddings.embed_documents(docs)\n",
        "\n",
        "print(f\"Embedding Dimension Output (Query): {len(embedded_query)}\")\n",
        "print(f\"Embedding Dimension Output (Docs): {len(embedded_docs[0])}\")\n",
        "\"\"\"\n",
        "\n",
        "# Overridden version of the LlamaCppEmbeddings class\n",
        "from typing import List\n",
        "from langchain_community.embeddings.llamacpp import LlamaCppEmbeddings\n",
        "\n",
        "\n",
        "class CustomLlamaCppEmbeddings(LlamaCppEmbeddings):\n",
        "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
        "        \"\"\"Embed a list of documents using the Llama model.\n",
        "\n",
        "        Args:\n",
        "            texts: The list of texts to embed.\n",
        "\n",
        "        Returns:\n",
        "            List of embeddings, one for each text.\n",
        "        \"\"\"\n",
        "        embeddings = [self.client.embed(text)[0] for text in texts]\n",
        "        return [list(map(float, e)) for e in embeddings]\n",
        "\n",
        "    def embed_query(self, text: str) -> List[float]:\n",
        "        \"\"\"Embed a query using the Llama model.\n",
        "\n",
        "        Args:\n",
        "            text: The text to embed.\n",
        "\n",
        "        Returns:\n",
        "            Embeddings for the text.\n",
        "        \"\"\"\n",
        "        embedding = self.client.embed(text)[0]\n",
        "        return list(map(float, embedding))\n",
        "\n",
        "\n",
        "c_embedder = CustomLlamaCppEmbeddings(model_path=model_path, n_gpu_layers=-1)\n",
        "embedded_query = c_embedder.embed_query([query])\n",
        "embedded_docs = c_embedder.embed_documents([docs])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Check custom embeddings\n",
        "\n",
        "- To check whether the embedding results are output as expected, I output the dimensions of each embedding vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution_count": 11
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Query embedding dimension: 1024\n",
            "Document embedding dimension: 1024\n"
          ]
        }
      ],
      "source": [
        "print(\"Query embedding dimension:\", len(embedded_query))\n",
        "print(\"Document embedding dimension:\", len(embedded_docs[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## The similarity calculation results\n",
        "\n",
        "We can use the vector representations of the query and documents to calculate similarity.\n",
        "Here, we use the [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) provided by scikit-learn.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution_count": 9
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.8711899]\n",
            "[Query] What is LangChain?\n",
            "====================================\n",
            "[0] similarity: 0.871 | LangChain is an open-source framework designed to facilitate the development of applications powered by large language models (LLMs). It provides tools and components to build end-to-end workflows for tasks like document retrieval, chatbots, summarization, data analysis, and more.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Calculate Cosine Similarity\n",
        "similarities = cosine_similarity([embedded_query], embedded_docs)[0]\n",
        "print(similarities)\n",
        "\n",
        "# Sort indices in ascending order.\n",
        "sorted_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "print(f\"[Query] {query}\\n====================================\")\n",
        "for i, idx in enumerate(sorted_indices):\n",
        "    print(f\"[{i}] similarity: {similarities[idx]:.3f} | {docs[idx]}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "----\n",
        "This concludes the **Llama-cpp Embeddings With Langchain** tutorial in the style of the original reference notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-tutorial",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
