{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RunnableWithMessageHistory\n",
        "\n",
        "- Author: [Secludor](https://github.com/Secludor)\n",
        "- Design: \n",
        "- Peer Review: \n",
        "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/03-OutputParser/02-CommaSeparatedListOutputParser.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/03-OutputParser/02-CommaSeparatedListOutputParser.ipynb)\n",
        "\n",
        "## Overview\n",
        "`RunnableWithMessageHistory`는 LangChain에서 대화 기록을 관리하기 위한 강력한 도구입니다. 이 클래스는 다른 Runnable을 래핑하여 채팅 메시지 기록을 관리하고 업데이트합니다. \n",
        "\n",
        "이 클래스를 사용하면 기존 체인(또는 Runnable) 위에 대화 이력을 쉽게 추가하고 관리할 수 있으며, 사용자 세션별로 대화 맥락을 이어가는 챗봇/에이전트를 구현할 수 있습니다.\n",
        "\n",
        "**다양한 입력/출력 형식 지원**\n",
        "- 이 래퍼는 감싼 Runnable(예: 체인, LLMChain 등)이 입력받거나 출력하는 형식이 메시지든, 또는 파이썬 딕셔너리 형태이든 유연하게 연동 가능합니다.\n",
        "\n",
        "**세션 단위 관리**\n",
        "- “session_id”나 “user_id + conversation_id” 등으로 식별자를 구성하여, 동일 사용자의 동일 세션에서 일관된 대화 이력을 불러오고 이어갈 수 있습니다.\n",
        "\n",
        "**기존 메모리/ConversationChain의 대안**\n",
        "- 예전 버전의 LangChain에 있던 메모리나 ConversationChain 클래스보다 보다 강력하고 유연한 방법으로 대화 이력을 관리하도록 만들어졌습니다.\n",
        "\n",
        "### 요약\n",
        "- `RunnableWithMessageHistory`는 애플리케이션의 상태를 유지하고, 사용자 경험을 향상시키며, 더 정교한 응답 메커니즘을 구현할 수 있게 해주는 새로운 표준 방식의 대화 이력 관리 도구입니다.\n",
        "  - 다양한 형태의 입력/출력 그리고 세션 식별 방식을 지원하며,\n",
        "  - 기존 `ConversationChain`보다 더 유연한 구성을 할 수 있게 해 줍니다.\n",
        "\n",
        "\n",
        "### Table of Contents\n",
        "\n",
        "- [Overview](#overview)  \n",
        "- [Environment Setup](#environment-setup)  \n",
        "- [Tutorial](#tutorial)\n",
        "- [In-Memory Conversation History](#in-memory-conversation-history)\n",
        "- [Example of Runnables with Using Veriety Keys](#example-of-runnables-with-using-veriety-keys)\n",
        "- [Persistent Storage](#persistent-storage)\n",
        "\n",
        "### References\n",
        "\n",
        "- [LangChain Core API Documentation - RunnableWithMessageHistory](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html)\n",
        "- [LangChain Expression Language Documentation - Message History](https://python.langchain.com/docs/expression_language/how_to/message_history)\n",
        "- [LangChain Community Documentation - Chat History](https://python.langchain.com/docs/modules/memory/chat_messages/chat_history)\n",
        "- [GitHub Discussion - RunnableWithMessageHistory Usage](https://github.com/langchain-ai/langchain/discussions/20511)\n",
        "- [RAGStack AI Documentation - RunnableWithMessageHistory](https://datastax.github.io/ragstack-ai/api_reference/0.5.0/langchain/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Environment Setup\n",
        "\n",
        "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
        "\n",
        "**[Note]**\n",
        "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
        "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%capture --no-stderr\n",
        "%pip install langchain-opentutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "from langchain_opentutorial import package\n",
        "\n",
        "package.install(\n",
        "    [\n",
        "        \"langsmith\",\n",
        "        \"langchain_openai\",\n",
        "        \"langchain_core\",\n",
        "        \"langchain_community\",\n",
        "    ],\n",
        "    verbose=False,\n",
        "    upgrade=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Environment variables have been set successfully.\n"
          ]
        }
      ],
      "source": [
        "# Set environment variables\n",
        "from langchain_opentutorial import set_env\n",
        "\n",
        "set_env(\n",
        "    {\n",
        "        \"OPENAI_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_API_KEY\": \"\",\n",
        "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
        "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
        "        \"LANGCHAIN_PROJECT\": \"08-RunnableWithMessageHistory\",\n",
        "    }\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can alternatively set `OPENAI_API_KEY` in `.env` file and load it. \n",
        "\n",
        "[Note] This is not necessary if you've already set `OPENAI_API_KEY` in previous steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv(override=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tutorial\n",
        "메시지 기록을 관리하는 것은 대화형 애플리케이션 또는 복잡한 데이터 처리 작업에서 매우 중요합니다. 메시지 기록을 효과적으로 관리하려면 다음 두 가지 주요 요소가 필요합니다.\n",
        "\n",
        "1. **Runnable**: 주로 Retriever, Chain 과 같이 `BaseChatMessageHistory` 와 상호작용하는 `runnable` 객체입니다.\n",
        "\n",
        "2. **`BaseChatMessageHistory`의 인스턴스를 반환하는 호출 가능한 객체(callable)**: 메시지 기록을 관리하기 위한 객체입니다. 이 객체는 메시지 기록을 저장, 검색, 업데이트하는 데 사용됩니다. 메시지 기록은 대화의 맥락을 유지하고, 사용자의 이전 입력에 기반한 응답을 생성하는 데 필요합니다.\n",
        "\n",
        "메시지 기록을 구현하는 데에는 여러 방법이 있으며, [memory integrations](https://integrations.langchain.com/memory) 페이지에는 다양한 저장소 옵션과 통합 방법이 소개되어 있습니다.\n",
        "\n",
        "여기서는 두 가지 주요 방법을 살펴보겠습니다.\n",
        "\n",
        "1. **인메모리 `ChatMessageHistory` 사용**\n",
        "\n",
        "   - 이 방법은 메모리 내에서 메시지 기록을 관리합니다. 주로 개발 단계나 간단한 애플리케이션에서 사용됩니다. 인메모리 방식은 빠른 접근 속도를 제공하지만, 애플리케이션을 재시작할 때 메시지 기록이 사라지는 단점이 있습니다.\n",
        "\n",
        "2. **`RedisChatMessageHistory`를 사용하여 영구적인 저장소 활용**\n",
        "   - Redis를 사용하는 방법은 메시지 기록을 영구적으로 저장할 수 있게 해줍니다. Redis는 높은 성능을 제공하는 오픈 소스 인메모리 데이터 구조 저장소로, 분산 환경에서도 안정적으로 메시지 기록을 관리할 수 있습니다. 이 방법은 복잡한 애플리케이션 또는 장기간 운영되는 서비스에 적합합니다.\n",
        "\n",
        "메시지 기록을 관리하는 방법을 선택할 때는 애플리케이션의 요구사항, 예상되는 트래픽 양, 메시지 데이터의 중요성 및 보존 기간 등을 고려해야 합니다. 인메모리 방식은 구현이 간단하고 빠르지만, 데이터의 영구성이 요구되는 경우 Redis와 같은 영구적인 저장소를 사용하는 것이 더 적합할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "model = ChatOpenAI()\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"당신은 {ability} 에 능숙한 어시스턴트입니다. 20자 이내로 응답하세요\",\n",
        "        ),\n",
        "        # 대화 기록을 변수로 사용, history 가 MessageHistory 의 key 가 됨\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "        (\"human\", \"{input}\"),  # 사용자 입력을 변수로 사용\n",
        "    ]\n",
        ")\n",
        "runnable = prompt | model  # 프롬프트와 모델을 연결하여 runnable 객체 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## In-Memory Conversation History\n",
        "\n",
        "아래는 채팅 기록이 메모리에 저장되는 간단한 예시입니다.\n",
        "\n",
        "`RunnableWithMessageHistory` 설정 매개변수\n",
        "\n",
        "- `runnable`\n",
        "- `BaseChatMessageHistory` 이거나 상속받은 객체. ex) `ChatMessageHistory`\n",
        "- `input_messages_key`: chain 을 invoke() 할때 사용자 쿼리 입력으로 지정하는 key\n",
        "- `history_messages_key`: 대화 기록으로 지정하는 key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "\n",
        "store = {}  # 세션 기록을 저장할 딕셔너리\n",
        "\n",
        "\n",
        "# 세션 ID를 기반으로 세션 기록을 가져오는 함수\n",
        "def get_session_history(session_ids: str) -> BaseChatMessageHistory:\n",
        "    print(session_ids)\n",
        "    if session_ids not in store:  # 세션 ID가 store에 없는 경우\n",
        "        # 새로운 ChatMessageHistory 객체를 생성하여 store에 저장\n",
        "        store[session_ids] = ChatMessageHistory()\n",
        "    return store[session_ids]  # 해당 세션 ID에 대한 세션 기록 반환\n",
        "\n",
        "\n",
        "with_message_history = (\n",
        "    RunnableWithMessageHistory(  # RunnableWithMessageHistory 객체 생성\n",
        "        runnable,  # 실행할 Runnable 객체\n",
        "        get_session_history,  # 세션 기록을 가져오는 함수\n",
        "        input_messages_key=\"input\",  # 입력 메시지의 키\n",
        "        history_messages_key=\"history\",  # 기록 메시지의 키\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`input_massage_key` sets the key to processing the latest input massage, and `history_messages_key` sets the key to add the previous massage history.\n",
        "\n",
        "다음의 코드를 보면 `RunnableWithMessageHistory` 의 초기값에 `session_id` 키를 Default 로 삽입하는 것을 볼 수 있으며, 이 코드로 인하여 `RunnableWithMessageHistory` 는 대화 스레드 관리를 `session_id` 로 한다는 것을 간접적으로 알 수 있습니다.\n",
        "\n",
        "즉, 대화 스레드별 관리는 `session_id` 별로 구현함을 알 수 있습니다.\n",
        "\n",
        "참고 코드: `RunnableWithMessageHistory` 구현을 참고해 보면,\n",
        "\n",
        "```python\n",
        "if history_factory_config:\n",
        "    _config_specs = history_factory_config\n",
        "else:\n",
        "    # If not provided, then we'll use the default session_id field\n",
        "    _config_specs = [\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"session_id\",\n",
        "            annotation=str,\n",
        "            name=\"Session ID\",\n",
        "            description=\"Unique identifier for a session.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "    ]\n",
        "```\n",
        "\n",
        "따라서, `invoke()` 시 `config={\"configurable\": {\"session_id\": \"세션ID입력\"}}` 코드를 반드시 지정해 주어야 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "abc123\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Trigonometric function that represents the ratio of the adjacent side to the hypotenuse in a right triangle.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 47, 'total_tokens': 70, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-f386f7c9-b70f-491d-9cce-cc955f5d9341-0', usage_metadata={'input_tokens': 47, 'output_tokens': 23, 'total_tokens': 70, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history.invoke(\n",
        "    # 수학 관련 질문 \"코사인의 의미는 무엇인가요?\"를 입력으로 전달합니다.\n",
        "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
        "    # 설정 정보로 세션 ID \"abc123\"을 전달합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you input the same `session_id` , 이전 대화 스레드의 내용을 가져오기 때문에 이어서 대화가 가능합니다! (이러한 연속적인 대화를 세션이라고 부릅니다.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "abc123\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='직각삼각형에서 인접변과 빗변의 비율을 나타내는 삼각함수입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 94, 'total_tokens': 136, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9df2486d-0b2c-4cfc-8e43-20878767af7b-0', usage_metadata={'input_tokens': 94, 'output_tokens': 42, 'total_tokens': 136, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 메시지 기록을 포함하여 호출합니다.\n",
        "with_message_history.invoke(\n",
        "    # 능력과 입력을 설정합니다.\n",
        "    {\"ability\": \"math\", \"input\": \"이전의 내용을 한글로 답변해 주세요.\"},\n",
        "    # 설정 옵션을 지정합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "하지만 다른 `session_id` 를 지정하면 대화기록이 없기 때문에 답변을 제대로 수행하지 못합니다.\n",
        "\n",
        "(아래의 예시는 `session_id` : `def234` 는 존재하지 않기 때문에 엉뚱한 답변을 하는 것을 확인할 수 있습니다)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "def234\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "AIMessage(content='수학에 능숙한 어시스턴트입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 58, 'total_tokens': 78, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4b1089f8-0179-4edb-86d8-b85557f5b4bf-0', usage_metadata={'input_tokens': 58, 'output_tokens': 20, 'total_tokens': 78, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 새로운 session_id로 인해 이전 대화 내용을 기억하지 않습니다.\n",
        "with_message_history.invoke(\n",
        "    # 수학 능력과 입력 메시지를 전달합니다.\n",
        "    {\"ability\": \"math\", \"input\": \"이전의 내용을 한글로 답변해 주세요\"},\n",
        "    # 새로운 session_id를 설정합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"def234\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "메시지 기록을 추적하는 데 사용되는 구성 매개변수는 `ConfigurableFieldSpec` 객체의 리스트를 `history_factory_config` 매개변수로 전달하여 사용자 정의할 수 있습니다.\n",
        "\n",
        "이렇게 `history_factory_config` 를 새로 설정하게 되면 기존 `session_id` 설정을 덮어쓰게 됩니다.\n",
        "\n",
        "아래 예시에서는 `user_id`와 `conversation_id`라는 두 가지 매개변수를 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import ConfigurableFieldSpec\n",
        "\n",
        "store = {}  # 빈 딕셔너리를 초기화합니다.\n",
        "\n",
        "\n",
        "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
        "    # 주어진 user_id와 conversation_id에 해당하는 세션 기록을 반환합니다.\n",
        "    if (user_id, conversation_id) not in store:\n",
        "        # 해당 키가 store에 없으면 새로운 ChatMessageHistory를 생성하여 저장합니다.\n",
        "        store[(user_id, conversation_id)] = ChatMessageHistory()\n",
        "    return store[(user_id, conversation_id)]\n",
        "\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    runnable,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\",\n",
        "    history_factory_config=[  # 기존의 \"session_id\" 설정을 대체하게 됩니다.\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"user_id\",  # get_session_history 함수의 첫 번째 인자로 사용됩니다.\n",
        "            annotation=str,\n",
        "            name=\"User ID\",\n",
        "            description=\"사용자의 고유 식별자입니다.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"conversation_id\",  # get_session_history 함수의 두 번째 인자로 사용됩니다.\n",
        "            annotation=str,\n",
        "            name=\"Conversation ID\",\n",
        "            description=\"대화의 고유 식별자입니다.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='A trigonometric function in mathematics.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 46, 'total_tokens': 55, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-321df1d0-c1e8-488a-9d40-bf1dd40bd4fe-0', usage_metadata={'input_tokens': 46, 'output_tokens': 9, 'total_tokens': 55, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history.invoke(\n",
        "    # 능력(ability)과 입력(input)을 포함한 딕셔너리를 전달합니다.\n",
        "    {\"ability\": \"math\", \"input\": \"what is cosine?\"},\n",
        "    # 설정(config) 딕셔너리를 전달합니다.\n",
        "    config={\"configurable\": {\"user_id\": \"123\", \"conversation_id\": \"abc\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Example of Runnables with Using Veriety Keys\n",
        "\n",
        "### Messages 객체를 입력, dict 형태의 출력\n",
        "\n",
        "메시지를 입력으로 받고 딕셔너리를 출력으로 반환하는 경우입니다.\n",
        "\n",
        "- [중요]: `input_messages_key`=\"input\" 을 생략합니다. 그럼 입력으로 Message 객체를 넣도록 설정하게 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'output_message': AIMessage(content='In mathematics, the cosine of an angle in a right-angled triangle is defined as the ratio of the length of the side adjacent to the angle to the length of the hypotenuse. It is denoted by the function cos(x) or cos θ. The cosine function is periodic with a period of 2π and is one of the fundamental trigonometric functions.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 77, 'prompt_tokens': 14, 'total_tokens': 91, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-73054daf-2319-4c1c-9939-17adc272b0d7-0', usage_metadata={'input_tokens': 14, 'output_tokens': 77, 'total_tokens': 91, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# chain 생성\n",
        "chain = RunnableParallel({\"output_message\": ChatOpenAI()})\n",
        "\n",
        "\n",
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    # 세션 ID에 해당하는 대화 기록이 저장소에 없으면 새로운 ChatMessageHistory를 생성합니다.\n",
        "    if session_id not in store:\n",
        "        store[session_id] = ChatMessageHistory()\n",
        "    # 세션 ID에 해당하는 대화 기록을 반환합니다.\n",
        "    return store[session_id]\n",
        "\n",
        "\n",
        "# 체인에 대화 기록 기능을 추가한 RunnableWithMessageHistory 객체를 생성합니다.\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    # # 입력 메시지의 키를 \"input\"으로 설정합니다.(생략시 Message 객체로 입력)\n",
        "    # input_messages_key=\"input\",\n",
        "    # 출력 메시지의 키를 \"output_message\"로 설정합니다. (생략시 Message 객체로 출력)\n",
        "    output_messages_key=\"output_message\",\n",
        ")\n",
        "\n",
        "# 주어진 메시지와 설정으로 체인을 실행합니다.\n",
        "with_message_history.invoke(\n",
        "    # 혹은 \"what is the definition of cosine?\" 도 가능\n",
        "    [HumanMessage(content=\"what is the definition of cosine?\")],\n",
        "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'output_message': AIMessage(content='수학에서 코사인은 직각삼각형에서 각의 대변에 인접한 변의 길이를 빗변의 길이로 나눈 비율로 정의됩니다. 이것은 cos(x) 또는 cos θ로 표시됩니다. 코사인 함수는 주기가 2π이며 기본 삼각함수 중 하나입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 112, 'prompt_tokens': 115, 'total_tokens': 227, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-43ae1d3d-2e66-458b-9b12-76709aa002bc-0', usage_metadata={'input_tokens': 115, 'output_tokens': 112, 'total_tokens': 227, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history.invoke(\n",
        "    # 이전의 답변에 대하여 한글로 답변을 재요청합니다.\n",
        "    [HumanMessage(content=\"이전의 내용을 한글로 답변해 주세요!\")],\n",
        "    # 설정 옵션을 딕셔너리 형태로 전달합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"abc123\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Message 객체를 입력, Message 객체를 출력\n",
        "\n",
        "- [중요]: `output_messages_key`=\"output_message\" 을 생략합니다. 그럼 출력으로 Message 객체를 반환합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "with_message_history = RunnableWithMessageHistory(\n",
        "    ChatOpenAI(),  # ChatOpenAI 언어 모델을 사용합니다.\n",
        "    get_session_history,  # 대화 세션 기록을 가져오는 함수를 지정합니다.\n",
        "    ## 입력 메시지의 키를 \"input\"으로 설정합니다.(생략시 Message 객체로 입력)\n",
        "    # input_messages_key=\"input\",\n",
        "    ## 출력 메시지의 키를 \"output_message\"로 설정합니다. (생략시 Message 객체로 출력)\n",
        "    # output_messages_key=\"output_message\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='코사인은 삼각함수 중 하나로, 직각삼각형에서 한 각의 대변과 빗변의 비율을 나타내는 값입니다. 각도가 주어졌을 때, 코사인은 인접 변의 길이를 빗변의 길이로 나눈 값입니다. 코사인은 삼각형의 각에 따라 변화하며, 삼각함수를 이용하여 삼각형의 변의 길이나 각의 크기를 구하는 데 사용됩니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 163, 'prompt_tokens': 24, 'total_tokens': 187, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e29cc206-f570-4978-9baa-2d5eb7d5a811-0', usage_metadata={'input_tokens': 24, 'output_tokens': 163, 'total_tokens': 187, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history.invoke(\n",
        "    # 이전의 답변에 대하여 한글로 답변을 재요청합니다.\n",
        "    [HumanMessage(content=\"코사인의 의미는 무엇인가요?\")],\n",
        "    # 설정 옵션을 딕셔너리 형태로 전달합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"def123\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**모든 메시지 입력과 출력을 위한 단일 키를 가진 Dict**\n",
        "- 모든 입력 메시지와 출력 메시지에 대해 단일 키를 사용하는 방식입니다.\n",
        "- `itemgetter(\"input_messages\")`를 사용하여 입력 메시지를 추출합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    # \"input_messages\" 키를 사용하여 입력 메시지를 가져와 ChatOpenAI()에 전달합니다.\n",
        "    itemgetter(\"input_messages\") | ChatOpenAI(),\n",
        "    get_session_history,  # 세션 기록을 가져오는 함수입니다.\n",
        "    input_messages_key=\"input_messages\",  # 입력 메시지의 키를 지정합니다.\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='코사인은 삼각함수의 하나로, 직각삼각형에서의 각도에 대한 함수로 정의됩니다. 코사인은 직각삼각형의 빗변과 인접변의 길이의 비율을 나타내며, 주로 삼각함수를 이용하여 각도와 변의 길이 사이의 관계를 구하는데 사용됩니다. 코사인은 주로 삼각함수 표현식에서 cos로 표기되며, 주어진 각도에 대해 코사인 값을 구할 수 있습니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 172, 'prompt_tokens': 24, 'total_tokens': 196, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-e0f51aff-5cc3-45e0-9e25-131a94e72681-0', usage_metadata={'input_tokens': 24, 'output_tokens': 172, 'total_tokens': 196, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history.invoke(\n",
        "    {\"input_messages\": \"코사인의 의미는 무엇인가요?\"},\n",
        "    # 설정 옵션을 딕셔너리 형태로 전달합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"xyz123\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Persistent Storage\n",
        "\n",
        "영구 저장소(Persistent storage)는 프로그램이 종료되거나 시스템이 재부팅되더라도 데이터를 유지하는 저장 메커니즘을 말합니다. 이는 데이터베이스, 파일 시스템, 또는 기타 비휘발성 저장 장치를 통해 구현될 수 있습니다.\n",
        "\n",
        "영구 저장소는 애플리케이션의 상태를 저장하고, 사용자 설정을 유지하며, **장기간 데이터를 보존하는 데 필수적**입니다. 이를 통해 프로그램은 이전 실행에서 중단된 지점부터 다시 시작할 수 있으며, **사용자는 데이터 손실 없이 작업을 계속** 할 수 있습니다.\n",
        "\n",
        "- `RunnableWithMessageHistory`는 `get_session_history` 호출 가능 객체가 채팅 메시지 기록을 어떻게 검색하는지에 대해 독립적입니다.\n",
        "- 로컬 파일 시스템을 사용하는 예제는 [여기](https://github.com/langchain-ai/langserve/blob/main/examples/chat_with_persistence_and_user/server.py)를 참조하세요.\n",
        "- 아래에서는 **Redis** 를 사용하는 방법을 보여줍니다. 다른 제공자를 사용하여 채팅 메시지 기록을 구현하는 방법은 [memory integrations](https://integrations.langchain.com/memory) 페이지를 확인하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### install Redis\n",
        "\n",
        "Redis가 설치되어 있지 않다면 먼저 설치해야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -qU redis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Redis 서버 구동\n",
        "\n",
        "기존에 연결할 Redis 배포가 없는 경우, 로컬 Redis Stack 서버를 시작합니다.\n",
        "\n",
        "다음은 Docker 로 Redis 서버를 구동하는 명령어입니다.\n",
        "\n",
        "```bash\n",
        "docker run -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest\n",
        "```\n",
        "- d: 데몬 모드로 실행 (백그라운드 실행)\n",
        "- p {port}:6379: Redis 서버 포트 매핑\n",
        "- p 8001:8001: RedisInsight UI 포트 매핑\n",
        "redis/redis-stack:latest: 최신 Redis Stack 이미지 사용\n",
        "\n",
        "If it doesn't work, \n",
        "- check the status of docker. (It should be running)\n",
        "- check the port is empty. (만일 해당 포트가 이미 점유중이라면, 점유중인 프로세스를 종료하거나 다른 포트를 이용하세요.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`REDIS_URL` 변수에 Redis 데이터베이스의 연결 URL을 할당합니다.\n",
        "\n",
        "- URL은 `\"redis://localhost:{port}/0\"`로 설정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Redis 서버의 URL을 지정합니다.\n",
        "REDIS_URL = \"redis://localhost:6378/0\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "메시지 기록 구현을 업데이트하려면 새로운 호출 가능한 객체를 정의하고, 이번에는 RedisChatMessageHistory의 인스턴스를 반환하면 됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.chat_message_histories import RedisChatMessageHistory\n",
        "\n",
        "\n",
        "def get_message_history(session_id: str) -> RedisChatMessageHistory:\n",
        "    # 세션 ID를 기반으로 RedisChatMessageHistory 객체를 반환합니다.\n",
        "    return RedisChatMessageHistory(session_id, url=REDIS_URL)\n",
        "\n",
        "\n",
        "with_message_history = RunnableWithMessageHistory(\n",
        "    runnable,  # 실행 가능한 객체\n",
        "    get_message_history,  # 메시지 기록을 가져오는 함수\n",
        "    input_messages_key=\"input\",  # 입력 메시지의 키\n",
        "    history_messages_key=\"history\",  # 기록 메시지의 키\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이전과 동일한 방식으로 호출할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Represents the ratio of the adjacent side to the hypotenuse in a right triangle.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 142, 'total_tokens': 161, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-baf1c2dd-94e5-4c08-bbfd-5e9f96aa7d62-0', usage_metadata={'input_tokens': 142, 'output_tokens': 19, 'total_tokens': 161, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history.invoke(\n",
        "    # 수학 관련 질문 \"코사인의 의미는 무엇인가요?\"를 입력으로 전달합니다.\n",
        "    {\"ability\": \"math\", \"input\": \"What does cosine mean?\"},\n",
        "    # 설정 옵션으로 세션 ID를 \"redis123\" 로 지정합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"redis123\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "동일한 `session_id`를 사용하여 두 번째 호출을 수행합니다. 이번에는 이전의 답변을 한글로 답변해 달라는 요청을 해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='직각삼각형에서 인접변과 빗변의 비율을 나타냅니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 36, 'prompt_tokens': 186, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-778e54e9-65ed-4020-b3f8-5f81f8d898b7-0', usage_metadata={'input_tokens': 186, 'output_tokens': 36, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history.invoke(\n",
        "    # 이전 답변에 대한 한글 번역을 요청합니다.\n",
        "    {\"ability\": \"math\", \"input\": \"이전의 답변을 한글로 번역해 주세요.\"},\n",
        "    # 설정 값으로 세션 ID를 \"foobar\"로 지정합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"redis123\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이번에는 다른 `session_id`를 사용하여 질문을 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='수학에 능숙한 도우미입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 105, 'total_tokens': 123, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-8d41983f-dbbf-4340-a5f1-322ff6a98188-0', usage_metadata={'input_tokens': 105, 'output_tokens': 18, 'total_tokens': 123, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "with_message_history.invoke(\n",
        "    # 이전 답변에 대한 한글 번역을 요청합니다.\n",
        "    {\"ability\": \"math\", \"input\": \"이전의 답변을 한글로 번역해 주세요.\"},\n",
        "    # 설정 값으로 세션 ID를 \"redis456\"로 지정합니다.\n",
        "    config={\"configurable\": {\"session_id\": \"redis456\"}},\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "마지막 답변은 이전 대화기록이 없으므로, 제대로 된 답변을 받을 수 없습니다."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "langchain-opentutorial-A2cWC-y3-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
