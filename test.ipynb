# ConversationBufferWindowMemory

- Author: [ulysyszh](https://github.com/ulysyszh)
- Design: [ulysyszh](https://github.com/ulysyszh)
- Peer Review: [Kenny Jung](https://www.linkedin.com/in/kwang-yong-jung)
- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)

## Overview

`ConversationEntityMemory` allows the conversation system to retain facts about specific entities mentioned during the dialogue.

In this case, Extracting information about entities from the conversation using a large language model.

Accumulating knowledge about these entities over time using the same large language model.

### Table of Contents
- [Overview](#overview)
- [Environment Setup](#environment-setup)
- [Example](#example)
- [Retrieving Entity Memory](#retrieving-entity-memory)

### References
- [LangChain Python API Reference > langchain: 0.3.13 > memory > ConversationEntityMemory](https://python.langchain.com/api_reference/langchain/memory/langchain.memory.entity.ConversationEntityMemory.html)

## Environment Setup
# Install required packages
!pip install langchain langchain-community langchain-opentutorial

from langchain_community.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory.entity import ConversationEntityMemory
from langchain_opentutorial import package

openai = ChatOpenAI(model="gpt-4o-mini")

package.install(
    [
        "langsmith",
        "langchain",
        "langchain_core",
        "langchain-anthropic",
        "langchain_community",
        "langchain_text_splitters",
        "langchain_openai",
    ],
    verbose=False,
    upgrade=False,
)

# Set environment variables
from langchain_opentutorial import set_env

set_env(
    {
        "OPENAI_API_KEY": "",
        "LANGCHAIN_API_KEY": "",
        "LANGCHAIN_TRACING_V2": "true",
        "LANGCHAIN_ENDPOINT": "https://api.smith.langchain.com",
        "LANGCHAIN_PROJECT": "ConversationEntityMemory",
    }
)

from dotenv import load_dotenv
load_dotenv(override=True)

## Example Setup
from langchain.prompts import PromptTemplate

entity_memory_conversation_template = PromptTemplate(
    input_variables=["entities", "history", "input"],
    template="""
You are an assistant to a human, powered by a large language model trained by OpenAI.

You assist with various tasks, from answering simple questions to providing detailed discussions on a wide range of topics. You can generate human-like text, allowing natural conversations and coherent, relevant responses.

You constantly learn and improve, processing large amounts of text to provide accurate and informative responses. You can use personalized information provided in the context below, along with your own generated knowledge.

Context:
{entities}

Current conversation:
{history}
Last line:
Human: {input}
You:
"""
)

## Online Bank Account Opening Conversation Example
llm = ChatOpenAI(temperature=0)

conversation = ConversationChain(
    llm=llm,
    prompt=entity_memory_conversation_template,
    memory=ConversationEntityMemory(llm=llm),
)

## Retrieving Conversation History
# Input conversation
response = conversation.predict(
    input=(
        "Amelia is an award-winning landscape photographer who has traveled around the globe capturing natural wonders. "
        "David is a wildlife conservationist dedicated to protecting endangered species. "
        "They are planning to open a nature-inspired photography gallery and learning center that raises funds for conservation projects."
    )
)

# Print the entity memory
print(conversation.memory.entity_store.store)
